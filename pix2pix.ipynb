{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/bkkaggle/pytorch-CycleGAN-and-pix2pix/blob/master/pix2pix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7wNjDKdQy35h"
   },
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TRm-USlsHgEV"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pt3igws3eiVp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('./pytorch-CycleGAN-and-pix2pix/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z1EySlOXwwoa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch>=1.4.0 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (2.7.0+cu128)\n",
      "Requirement already satisfied: torchvision>=0.5.0 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (0.22.0+cu128)\n",
      "Collecting dominate>=2.4.0 (from -r requirements.txt (line 3))\n",
      "  Using cached dominate-2.9.1-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Collecting visdom>=0.1.8.8 (from -r requirements.txt (line 4))\n",
      "  Downloading visdom-0.2.4.tar.gz (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting wandb (from -r requirements.txt (line 5))\n",
      "  Downloading wandb-0.19.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: filelock in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (4.11.0)\n",
      "Requirement already satisfied: setuptools in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (75.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.7.1.26 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (9.7.1.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (1.13.0.11)\n",
      "Requirement already satisfied: triton==3.3.0 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.3.0)\n",
      "Requirement already satisfied: numpy in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (10.4.0)\n",
      "Requirement already satisfied: scipy in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.13.1)\n",
      "Requirement already satisfied: requests in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.32.3)\n",
      "Requirement already satisfied: tornado in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (6.4.1)\n",
      "Requirement already satisfied: six in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.16.0)\n",
      "Requirement already satisfied: jsonpatch in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.33)\n",
      "Requirement already satisfied: websocket-client in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.8.0)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 5)) (8.1.7)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 5))\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 5)) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 5)) (3.10.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 5)) (4.25.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 5)) (5.9.0)\n",
      "Requirement already satisfied: pydantic<3 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: pyyaml in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 5)) (6.0.1)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb->-r requirements.txt (line 5))\n",
      "  Downloading sentry_sdk-2.27.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setproctitle (from wandb->-r requirements.txt (line 5))\n",
      "  Downloading setproctitle-1.3.6-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5)) (4.0.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from pydantic<3->wandb->-r requirements.txt (line 5)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from pydantic<3->wandb->-r requirements.txt (line 5)) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.4.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.4.0->-r requirements.txt (line 1)) (2.1.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from jsonpatch->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.1)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /home/omerfarukaydin/anaconda3/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5)) (4.0.0)\n",
      "Using cached dominate-2.9.1-py2.py3-none-any.whl (29 kB)\n",
      "Downloading wandb-0.19.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading sentry_sdk-2.27.0-py2.py3-none-any.whl (340 kB)\n",
      "Downloading setproctitle-1.3.6-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Building wheels for collected packages: visdom\n",
      "  Building wheel for visdom (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for visdom: filename=visdom-0.2.4-py3-none-any.whl size=1408196 sha256=2a188dd400d8dabbb12836fcee8ca7dfb0b8f4f1a36d183f4c71b8eb6113496e\n",
      "  Stored in directory: /home/omerfarukaydin/.cache/pip/wheels/37/6c/38/64eeaa310e325aacda723e6df1f79ab5e9f31ba195264e04a8\n",
      "Successfully built visdom\n",
      "Installing collected packages: setproctitle, sentry-sdk, dominate, docker-pycreds, visdom, wandb\n",
      "Successfully installed docker-pycreds-0.4.0 dominate-2.9.1 sentry-sdk-2.27.0 setproctitle-1.3.6 visdom-0.2.4 wandb-0.19.10\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8daqlgVhw29P"
   },
   "source": [
    "# Datasets\n",
    "\n",
    "Download one of the official datasets with:\n",
    "\n",
    "-   `bash ./datasets/download_pix2pix_dataset.sh [cityscapes, night2day, edges2handbags, edges2shoes, facades, maps]`\n",
    "\n",
    "Or use your own dataset by creating the appropriate folders and adding in the images. Follow the instructions [here](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/docs/datasets.md#pix2pix-datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vrdOettJxaCc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specified [facades]\n",
      "WARNING: timestamping does nothing in combination with -O. See the manual\n",
      "for details.\n",
      "\n",
      "--2025-04-30 01:04:05--  http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/facades.tar.gz\n",
      "Resolving efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)... 128.32.244.190\n",
      "Connecting to efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)|128.32.244.190|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 30168306 (29M) [application/x-gzip]\n",
      "Saving to: ‘./datasets/facades.tar.gz’\n",
      "\n",
      "./datasets/facades. 100%[===================>]  28.77M   232KB/s    in 27s     \n",
      "\n",
      "2025-04-30 01:04:33 (1.08 MB/s) - ‘./datasets/facades.tar.gz’ saved [30168306/30168306]\n",
      "\n",
      "facades/\n",
      "facades/test/\n",
      "facades/test/27.jpg\n",
      "facades/test/5.jpg\n",
      "facades/test/72.jpg\n",
      "facades/test/1.jpg\n",
      "facades/test/10.jpg\n",
      "facades/test/100.jpg\n",
      "facades/test/101.jpg\n",
      "facades/test/102.jpg\n",
      "facades/test/103.jpg\n",
      "facades/test/104.jpg\n",
      "facades/test/105.jpg\n",
      "facades/test/106.jpg\n",
      "facades/test/11.jpg\n",
      "facades/test/12.jpg\n",
      "facades/test/13.jpg\n",
      "facades/test/14.jpg\n",
      "facades/test/15.jpg\n",
      "facades/test/16.jpg\n",
      "facades/test/17.jpg\n",
      "facades/test/18.jpg\n",
      "facades/test/19.jpg\n",
      "facades/test/2.jpg\n",
      "facades/test/20.jpg\n",
      "facades/test/21.jpg\n",
      "facades/test/22.jpg\n",
      "facades/test/23.jpg\n",
      "facades/test/24.jpg\n",
      "facades/test/25.jpg\n",
      "facades/test/26.jpg\n",
      "facades/test/50.jpg\n",
      "facades/test/51.jpg\n",
      "facades/test/52.jpg\n",
      "facades/test/53.jpg\n",
      "facades/test/54.jpg\n",
      "facades/test/55.jpg\n",
      "facades/test/56.jpg\n",
      "facades/test/57.jpg\n",
      "facades/test/58.jpg\n",
      "facades/test/59.jpg\n",
      "facades/test/6.jpg\n",
      "facades/test/60.jpg\n",
      "facades/test/61.jpg\n",
      "facades/test/62.jpg\n",
      "facades/test/63.jpg\n",
      "facades/test/64.jpg\n",
      "facades/test/65.jpg\n",
      "facades/test/66.jpg\n",
      "facades/test/67.jpg\n",
      "facades/test/68.jpg\n",
      "facades/test/69.jpg\n",
      "facades/test/7.jpg\n",
      "facades/test/70.jpg\n",
      "facades/test/71.jpg\n",
      "facades/test/73.jpg\n",
      "facades/test/74.jpg\n",
      "facades/test/75.jpg\n",
      "facades/test/76.jpg\n",
      "facades/test/77.jpg\n",
      "facades/test/78.jpg\n",
      "facades/test/79.jpg\n",
      "facades/test/8.jpg\n",
      "facades/test/80.jpg\n",
      "facades/test/81.jpg\n",
      "facades/test/82.jpg\n",
      "facades/test/83.jpg\n",
      "facades/test/84.jpg\n",
      "facades/test/85.jpg\n",
      "facades/test/86.jpg\n",
      "facades/test/87.jpg\n",
      "facades/test/88.jpg\n",
      "facades/test/89.jpg\n",
      "facades/test/9.jpg\n",
      "facades/test/90.jpg\n",
      "facades/test/91.jpg\n",
      "facades/test/92.jpg\n",
      "facades/test/93.jpg\n",
      "facades/test/94.jpg\n",
      "facades/test/95.jpg\n",
      "facades/test/96.jpg\n",
      "facades/test/97.jpg\n",
      "facades/test/98.jpg\n",
      "facades/test/99.jpg\n",
      "facades/test/28.jpg\n",
      "facades/test/29.jpg\n",
      "facades/test/3.jpg\n",
      "facades/test/30.jpg\n",
      "facades/test/31.jpg\n",
      "facades/test/32.jpg\n",
      "facades/test/33.jpg\n",
      "facades/test/34.jpg\n",
      "facades/test/35.jpg\n",
      "facades/test/36.jpg\n",
      "facades/test/37.jpg\n",
      "facades/test/38.jpg\n",
      "facades/test/39.jpg\n",
      "facades/test/4.jpg\n",
      "facades/test/40.jpg\n",
      "facades/test/41.jpg\n",
      "facades/test/42.jpg\n",
      "facades/test/43.jpg\n",
      "facades/test/44.jpg\n",
      "facades/test/45.jpg\n",
      "facades/test/46.jpg\n",
      "facades/test/47.jpg\n",
      "facades/test/48.jpg\n",
      "facades/test/49.jpg\n",
      "facades/train/\n",
      "facades/train/1.jpg\n",
      "facades/train/10.jpg\n",
      "facades/train/100.jpg\n",
      "facades/train/101.jpg\n",
      "facades/train/102.jpg\n",
      "facades/train/103.jpg\n",
      "facades/train/104.jpg\n",
      "facades/train/105.jpg\n",
      "facades/train/106.jpg\n",
      "facades/train/107.jpg\n",
      "facades/train/108.jpg\n",
      "facades/train/109.jpg\n",
      "facades/train/11.jpg\n",
      "facades/train/110.jpg\n",
      "facades/train/111.jpg\n",
      "facades/train/112.jpg\n",
      "facades/train/113.jpg\n",
      "facades/train/114.jpg\n",
      "facades/train/115.jpg\n",
      "facades/train/116.jpg\n",
      "facades/train/117.jpg\n",
      "facades/train/118.jpg\n",
      "facades/train/119.jpg\n",
      "facades/train/12.jpg\n",
      "facades/train/120.jpg\n",
      "facades/train/121.jpg\n",
      "facades/train/122.jpg\n",
      "facades/train/123.jpg\n",
      "facades/train/124.jpg\n",
      "facades/train/125.jpg\n",
      "facades/train/126.jpg\n",
      "facades/train/309.jpg\n",
      "facades/train/31.jpg\n",
      "facades/train/310.jpg\n",
      "facades/train/311.jpg\n",
      "facades/train/312.jpg\n",
      "facades/train/313.jpg\n",
      "facades/train/314.jpg\n",
      "facades/train/315.jpg\n",
      "facades/train/316.jpg\n",
      "facades/train/317.jpg\n",
      "facades/train/318.jpg\n",
      "facades/train/319.jpg\n",
      "facades/train/32.jpg\n",
      "facades/train/320.jpg\n",
      "facades/train/321.jpg\n",
      "facades/train/322.jpg\n",
      "facades/train/323.jpg\n",
      "facades/train/324.jpg\n",
      "facades/train/325.jpg\n",
      "facades/train/326.jpg\n",
      "facades/train/327.jpg\n",
      "facades/train/328.jpg\n",
      "facades/train/329.jpg\n",
      "facades/train/390.jpg\n",
      "facades/train/391.jpg\n",
      "facades/train/392.jpg\n",
      "facades/train/393.jpg\n",
      "facades/train/394.jpg\n",
      "facades/train/395.jpg\n",
      "facades/train/396.jpg\n",
      "facades/train/397.jpg\n",
      "facades/train/398.jpg\n",
      "facades/train/399.jpg\n",
      "facades/train/4.jpg\n",
      "facades/train/40.jpg\n",
      "facades/train/400.jpg\n",
      "facades/train/41.jpg\n",
      "facades/train/42.jpg\n",
      "facades/train/43.jpg\n",
      "facades/train/44.jpg\n",
      "facades/train/45.jpg\n",
      "facades/train/46.jpg\n",
      "facades/train/47.jpg\n",
      "facades/train/48.jpg\n",
      "facades/train/49.jpg\n",
      "facades/train/5.jpg\n",
      "facades/train/50.jpg\n",
      "facades/train/51.jpg\n",
      "facades/train/52.jpg\n",
      "facades/train/53.jpg\n",
      "facades/train/54.jpg\n",
      "facades/train/55.jpg\n",
      "facades/train/56.jpg\n",
      "facades/train/57.jpg\n",
      "facades/train/58.jpg\n",
      "facades/train/59.jpg\n",
      "facades/train/6.jpg\n",
      "facades/train/60.jpg\n",
      "facades/train/61.jpg\n",
      "facades/train/222.jpg\n",
      "facades/train/223.jpg\n",
      "facades/train/224.jpg\n",
      "facades/train/225.jpg\n",
      "facades/train/226.jpg\n",
      "facades/train/227.jpg\n",
      "facades/train/228.jpg\n",
      "facades/train/229.jpg\n",
      "facades/train/23.jpg\n",
      "facades/train/230.jpg\n",
      "facades/train/231.jpg\n",
      "facades/train/232.jpg\n",
      "facades/train/233.jpg\n",
      "facades/train/234.jpg\n",
      "facades/train/235.jpg\n",
      "facades/train/236.jpg\n",
      "facades/train/237.jpg\n",
      "facades/train/238.jpg\n",
      "facades/train/239.jpg\n",
      "facades/train/24.jpg\n",
      "facades/train/240.jpg\n",
      "facades/train/241.jpg\n",
      "facades/train/242.jpg\n",
      "facades/train/243.jpg\n",
      "facades/train/244.jpg\n",
      "facades/train/245.jpg\n",
      "facades/train/156.jpg\n",
      "facades/train/157.jpg\n",
      "facades/train/158.jpg\n",
      "facades/train/159.jpg\n",
      "facades/train/16.jpg\n",
      "facades/train/160.jpg\n",
      "facades/train/161.jpg\n",
      "facades/train/162.jpg\n",
      "facades/train/163.jpg\n",
      "facades/train/164.jpg\n",
      "facades/train/165.jpg\n",
      "facades/train/166.jpg\n",
      "facades/train/167.jpg\n",
      "facades/train/168.jpg\n",
      "facades/train/169.jpg\n",
      "facades/train/17.jpg\n",
      "facades/train/170.jpg\n",
      "facades/train/171.jpg\n",
      "facades/train/172.jpg\n",
      "facades/train/173.jpg\n",
      "facades/train/174.jpg\n",
      "facades/train/175.jpg\n",
      "facades/train/176.jpg\n",
      "facades/train/177.jpg\n",
      "facades/train/178.jpg\n",
      "facades/train/179.jpg\n",
      "facades/train/18.jpg\n",
      "facades/train/180.jpg\n",
      "facades/train/181.jpg\n",
      "facades/train/182.jpg\n",
      "facades/train/183.jpg\n",
      "facades/train/184.jpg\n",
      "facades/train/185.jpg\n",
      "facades/train/186.jpg\n",
      "facades/train/187.jpg\n",
      "facades/train/188.jpg\n",
      "facades/train/189.jpg\n",
      "facades/train/19.jpg\n",
      "facades/train/127.jpg\n",
      "facades/train/155.jpg\n",
      "facades/train/190.jpg\n",
      "facades/train/221.jpg\n",
      "facades/train/246.jpg\n",
      "facades/train/27.jpg\n",
      "facades/train/29.jpg\n",
      "facades/train/308.jpg\n",
      "facades/train/33.jpg\n",
      "facades/train/350.jpg\n",
      "facades/train/370.jpg\n",
      "facades/train/39.jpg\n",
      "facades/train/62.jpg\n",
      "facades/train/270.jpg\n",
      "facades/train/271.jpg\n",
      "facades/train/272.jpg\n",
      "facades/train/273.jpg\n",
      "facades/train/274.jpg\n",
      "facades/train/275.jpg\n",
      "facades/train/276.jpg\n",
      "facades/train/277.jpg\n",
      "facades/train/278.jpg\n",
      "facades/train/279.jpg\n",
      "facades/train/28.jpg\n",
      "facades/train/280.jpg\n",
      "facades/train/281.jpg\n",
      "facades/train/282.jpg\n",
      "facades/train/283.jpg\n",
      "facades/train/284.jpg\n",
      "facades/train/285.jpg\n",
      "facades/train/286.jpg\n",
      "facades/train/287.jpg\n",
      "facades/train/288.jpg\n",
      "facades/train/289.jpg\n",
      "facades/train/351.jpg\n",
      "facades/train/352.jpg\n",
      "facades/train/353.jpg\n",
      "facades/train/354.jpg\n",
      "facades/train/355.jpg\n",
      "facades/train/356.jpg\n",
      "facades/train/357.jpg\n",
      "facades/train/358.jpg\n",
      "facades/train/359.jpg\n",
      "facades/train/36.jpg\n",
      "facades/train/360.jpg\n",
      "facades/train/361.jpg\n",
      "facades/train/362.jpg\n",
      "facades/train/363.jpg\n",
      "facades/train/364.jpg\n",
      "facades/train/365.jpg\n",
      "facades/train/366.jpg\n",
      "facades/train/367.jpg\n",
      "facades/train/368.jpg\n",
      "facades/train/369.jpg\n",
      "facades/train/37.jpg\n",
      "facades/train/63.jpg\n",
      "facades/train/64.jpg\n",
      "facades/train/65.jpg\n",
      "facades/train/66.jpg\n",
      "facades/train/67.jpg\n",
      "facades/train/68.jpg\n",
      "facades/train/69.jpg\n",
      "facades/train/7.jpg\n",
      "facades/train/70.jpg\n",
      "facades/train/71.jpg\n",
      "facades/train/72.jpg\n",
      "facades/train/73.jpg\n",
      "facades/train/74.jpg\n",
      "facades/train/75.jpg\n",
      "facades/train/76.jpg\n",
      "facades/train/77.jpg\n",
      "facades/train/78.jpg\n",
      "facades/train/79.jpg\n",
      "facades/train/8.jpg\n",
      "facades/train/80.jpg\n",
      "facades/train/81.jpg\n",
      "facades/train/82.jpg\n",
      "facades/train/83.jpg\n",
      "facades/train/84.jpg\n",
      "facades/train/85.jpg\n",
      "facades/train/86.jpg\n",
      "facades/train/87.jpg\n",
      "facades/train/88.jpg\n",
      "facades/train/89.jpg\n",
      "facades/train/9.jpg\n",
      "facades/train/90.jpg\n",
      "facades/train/91.jpg\n",
      "facades/train/92.jpg\n",
      "facades/train/93.jpg\n",
      "facades/train/94.jpg\n",
      "facades/train/95.jpg\n",
      "facades/train/96.jpg\n",
      "facades/train/97.jpg\n",
      "facades/train/98.jpg\n",
      "facades/train/99.jpg\n",
      "facades/train/128.jpg\n",
      "facades/train/129.jpg\n",
      "facades/train/13.jpg\n",
      "facades/train/130.jpg\n",
      "facades/train/131.jpg\n",
      "facades/train/132.jpg\n",
      "facades/train/133.jpg\n",
      "facades/train/134.jpg\n",
      "facades/train/135.jpg\n",
      "facades/train/136.jpg\n",
      "facades/train/137.jpg\n",
      "facades/train/138.jpg\n",
      "facades/train/139.jpg\n",
      "facades/train/14.jpg\n",
      "facades/train/140.jpg\n",
      "facades/train/141.jpg\n",
      "facades/train/142.jpg\n",
      "facades/train/143.jpg\n",
      "facades/train/144.jpg\n",
      "facades/train/145.jpg\n",
      "facades/train/146.jpg\n",
      "facades/train/147.jpg\n",
      "facades/train/148.jpg\n",
      "facades/train/149.jpg\n",
      "facades/train/15.jpg\n",
      "facades/train/150.jpg\n",
      "facades/train/151.jpg\n",
      "facades/train/152.jpg\n",
      "facades/train/153.jpg\n",
      "facades/train/154.jpg\n",
      "facades/train/191.jpg\n",
      "facades/train/192.jpg\n",
      "facades/train/193.jpg\n",
      "facades/train/194.jpg\n",
      "facades/train/195.jpg\n",
      "facades/train/196.jpg\n",
      "facades/train/197.jpg\n",
      "facades/train/198.jpg\n",
      "facades/train/199.jpg\n",
      "facades/train/2.jpg\n",
      "facades/train/20.jpg\n",
      "facades/train/200.jpg\n",
      "facades/train/201.jpg\n",
      "facades/train/202.jpg\n",
      "facades/train/203.jpg\n",
      "facades/train/204.jpg\n",
      "facades/train/205.jpg\n",
      "facades/train/206.jpg\n",
      "facades/train/207.jpg\n",
      "facades/train/208.jpg\n",
      "facades/train/209.jpg\n",
      "facades/train/21.jpg\n",
      "facades/train/210.jpg\n",
      "facades/train/211.jpg\n",
      "facades/train/212.jpg\n",
      "facades/train/213.jpg\n",
      "facades/train/214.jpg\n",
      "facades/train/215.jpg\n",
      "facades/train/216.jpg\n",
      "facades/train/217.jpg\n",
      "facades/train/218.jpg\n",
      "facades/train/219.jpg\n",
      "facades/train/22.jpg\n",
      "facades/train/220.jpg\n",
      "facades/train/247.jpg\n",
      "facades/train/248.jpg\n",
      "facades/train/249.jpg\n",
      "facades/train/25.jpg\n",
      "facades/train/250.jpg\n",
      "facades/train/251.jpg\n",
      "facades/train/252.jpg\n",
      "facades/train/253.jpg\n",
      "facades/train/254.jpg\n",
      "facades/train/255.jpg\n",
      "facades/train/256.jpg\n",
      "facades/train/257.jpg\n",
      "facades/train/258.jpg\n",
      "facades/train/259.jpg\n",
      "facades/train/26.jpg\n",
      "facades/train/260.jpg\n",
      "facades/train/261.jpg\n",
      "facades/train/262.jpg\n",
      "facades/train/263.jpg\n",
      "facades/train/264.jpg\n",
      "facades/train/265.jpg\n",
      "facades/train/266.jpg\n",
      "facades/train/267.jpg\n",
      "facades/train/268.jpg\n",
      "facades/train/269.jpg\n",
      "facades/train/330.jpg\n",
      "facades/train/331.jpg\n",
      "facades/train/332.jpg\n",
      "facades/train/333.jpg\n",
      "facades/train/334.jpg\n",
      "facades/train/335.jpg\n",
      "facades/train/336.jpg\n",
      "facades/train/337.jpg\n",
      "facades/train/338.jpg\n",
      "facades/train/339.jpg\n",
      "facades/train/34.jpg\n",
      "facades/train/340.jpg\n",
      "facades/train/341.jpg\n",
      "facades/train/342.jpg\n",
      "facades/train/343.jpg\n",
      "facades/train/344.jpg\n",
      "facades/train/345.jpg\n",
      "facades/train/346.jpg\n",
      "facades/train/347.jpg\n",
      "facades/train/348.jpg\n",
      "facades/train/349.jpg\n",
      "facades/train/35.jpg\n",
      "facades/train/290.jpg\n",
      "facades/train/291.jpg\n",
      "facades/train/292.jpg\n",
      "facades/train/293.jpg\n",
      "facades/train/294.jpg\n",
      "facades/train/295.jpg\n",
      "facades/train/296.jpg\n",
      "facades/train/297.jpg\n",
      "facades/train/298.jpg\n",
      "facades/train/299.jpg\n",
      "facades/train/3.jpg\n",
      "facades/train/30.jpg\n",
      "facades/train/300.jpg\n",
      "facades/train/301.jpg\n",
      "facades/train/302.jpg\n",
      "facades/train/303.jpg\n",
      "facades/train/304.jpg\n",
      "facades/train/305.jpg\n",
      "facades/train/306.jpg\n",
      "facades/train/307.jpg\n",
      "facades/train/371.jpg\n",
      "facades/train/372.jpg\n",
      "facades/train/373.jpg\n",
      "facades/train/374.jpg\n",
      "facades/train/375.jpg\n",
      "facades/train/376.jpg\n",
      "facades/train/377.jpg\n",
      "facades/train/378.jpg\n",
      "facades/train/379.jpg\n",
      "facades/train/38.jpg\n",
      "facades/train/380.jpg\n",
      "facades/train/381.jpg\n",
      "facades/train/382.jpg\n",
      "facades/train/383.jpg\n",
      "facades/train/384.jpg\n",
      "facades/train/385.jpg\n",
      "facades/train/386.jpg\n",
      "facades/train/387.jpg\n",
      "facades/train/388.jpg\n",
      "facades/train/389.jpg\n",
      "facades/val/\n",
      "facades/val/30.jpg\n",
      "facades/val/50.jpg\n",
      "facades/val/73.jpg\n",
      "facades/val/1.jpg\n",
      "facades/val/10.jpg\n",
      "facades/val/100.jpg\n",
      "facades/val/11.jpg\n",
      "facades/val/12.jpg\n",
      "facades/val/13.jpg\n",
      "facades/val/14.jpg\n",
      "facades/val/15.jpg\n",
      "facades/val/16.jpg\n",
      "facades/val/17.jpg\n",
      "facades/val/18.jpg\n",
      "facades/val/19.jpg\n",
      "facades/val/2.jpg\n",
      "facades/val/20.jpg\n",
      "facades/val/21.jpg\n",
      "facades/val/22.jpg\n",
      "facades/val/23.jpg\n",
      "facades/val/24.jpg\n",
      "facades/val/25.jpg\n",
      "facades/val/26.jpg\n",
      "facades/val/27.jpg\n",
      "facades/val/28.jpg\n",
      "facades/val/29.jpg\n",
      "facades/val/3.jpg\n",
      "facades/val/51.jpg\n",
      "facades/val/52.jpg\n",
      "facades/val/53.jpg\n",
      "facades/val/54.jpg\n",
      "facades/val/55.jpg\n",
      "facades/val/56.jpg\n",
      "facades/val/57.jpg\n",
      "facades/val/58.jpg\n",
      "facades/val/59.jpg\n",
      "facades/val/6.jpg\n",
      "facades/val/60.jpg\n",
      "facades/val/61.jpg\n",
      "facades/val/62.jpg\n",
      "facades/val/63.jpg\n",
      "facades/val/64.jpg\n",
      "facades/val/65.jpg\n",
      "facades/val/66.jpg\n",
      "facades/val/67.jpg\n",
      "facades/val/68.jpg\n",
      "facades/val/69.jpg\n",
      "facades/val/7.jpg\n",
      "facades/val/70.jpg\n",
      "facades/val/71.jpg\n",
      "facades/val/72.jpg\n",
      "facades/val/74.jpg\n",
      "facades/val/75.jpg\n",
      "facades/val/76.jpg\n",
      "facades/val/77.jpg\n",
      "facades/val/78.jpg\n",
      "facades/val/79.jpg\n",
      "facades/val/8.jpg\n",
      "facades/val/80.jpg\n",
      "facades/val/81.jpg\n",
      "facades/val/82.jpg\n",
      "facades/val/83.jpg\n",
      "facades/val/84.jpg\n",
      "facades/val/85.jpg\n",
      "facades/val/86.jpg\n",
      "facades/val/87.jpg\n",
      "facades/val/88.jpg\n",
      "facades/val/89.jpg\n",
      "facades/val/9.jpg\n",
      "facades/val/90.jpg\n",
      "facades/val/91.jpg\n",
      "facades/val/92.jpg\n",
      "facades/val/93.jpg\n",
      "facades/val/94.jpg\n",
      "facades/val/95.jpg\n",
      "facades/val/96.jpg\n",
      "facades/val/97.jpg\n",
      "facades/val/98.jpg\n",
      "facades/val/99.jpg\n",
      "facades/val/31.jpg\n",
      "facades/val/32.jpg\n",
      "facades/val/33.jpg\n",
      "facades/val/34.jpg\n",
      "facades/val/35.jpg\n",
      "facades/val/36.jpg\n",
      "facades/val/37.jpg\n",
      "facades/val/38.jpg\n",
      "facades/val/39.jpg\n",
      "facades/val/4.jpg\n",
      "facades/val/40.jpg\n",
      "facades/val/41.jpg\n",
      "facades/val/42.jpg\n",
      "facades/val/43.jpg\n",
      "facades/val/44.jpg\n",
      "facades/val/45.jpg\n",
      "facades/val/46.jpg\n",
      "facades/val/47.jpg\n",
      "facades/val/48.jpg\n",
      "facades/val/49.jpg\n",
      "facades/val/5.jpg\n"
     ]
    }
   ],
   "source": [
    "!bash ./datasets/download_pix2pix_dataset.sh facades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gdUz4116xhpm"
   },
   "source": [
    "# Pretrained models\n",
    "\n",
    "Download one of the official pretrained models with:\n",
    "\n",
    "-   `bash ./scripts/download_pix2pix_model.sh [edges2shoes, sat2map, map2sat, facades_label2photo, and day2night]`\n",
    "\n",
    "Or add your own pretrained model to `./checkpoints/{NAME}_pretrained/latest_net_G.pt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GC2DEP4M0OsS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: available models are edges2shoes, sat2map, map2sat, facades_label2photo, and day2night\n",
      "Specified [facades_label2photo]\n",
      "WARNING: timestamping does nothing in combination with -O. See the manual\n",
      "for details.\n",
      "\n",
      "--2025-04-30 01:04:41--  http://efrosgans.eecs.berkeley.edu/pix2pix/models-pytorch/facades_label2photo.pth\n",
      "Resolving efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)... 128.32.244.190\n",
      "Connecting to efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)|128.32.244.190|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 217704720 (208M)\n",
      "Saving to: ‘./checkpoints/facades_label2photo_pretrained/latest_net_G.pth’\n",
      "\n",
      "./checkpoints/facad 100%[===================>] 207.62M  14.3MB/s    in 16s     \n",
      "\n",
      "2025-04-30 01:04:57 (13.1 MB/s) - ‘./checkpoints/facades_label2photo_pretrained/latest_net_G.pth’ saved [217704720/217704720]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!bash ./scripts/download_pix2pix_model.sh facades_label2photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ python test.py --dataroot ./datasets/facades/testB/ --name facades_pix2pix --model test --netG unet_256 --direction BtoA --dataset_mode single --norm batch\n",
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/facades/testB/     \t[default: None]\n",
      "             dataset_mode: single                        \n",
      "                direction: BtoA                          \t[default: AtoB]\n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: test                          \n",
      "             model_suffix:                               \n",
      "               n_layers_D: 3                             \n",
      "                     name: facades_pix2pix               \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \t[default: resnet_9blocks]\n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \t[default: instance]\n",
      "                 num_test: 50                            \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: test                          \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: ./results/                    \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/omerfarukaydin/Desktop/pytorch-CycleGAN-and-pix2pix/test.py\", line 50, in <module>\n",
      "    dataset = create_dataset(opt)  # create a dataset given opt.dataset_mode and other options\n",
      "              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/omerfarukaydin/Desktop/pytorch-CycleGAN-and-pix2pix/data/__init__.py\", line 57, in create_dataset\n",
      "    data_loader = CustomDatasetDataLoader(opt)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/omerfarukaydin/Desktop/pytorch-CycleGAN-and-pix2pix/data/__init__.py\", line 73, in __init__\n",
      "    self.dataset = dataset_class(opt)\n",
      "                   ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/omerfarukaydin/Desktop/pytorch-CycleGAN-and-pix2pix/data/single_dataset.py\", line 19, in __init__\n",
      "    self.A_paths = sorted(make_dataset(opt.dataroot, opt.max_dataset_size))\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/omerfarukaydin/Desktop/pytorch-CycleGAN-and-pix2pix/data/image_folder.py\", line 25, in make_dataset\n",
      "    assert os.path.isdir(dir), '%s is not a valid directory' % dir\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: ./datasets/facades/testB/ is not a valid directory\n"
     ]
    }
   ],
   "source": [
    "!bash ./scripts/test_single.sh facades_single"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yFw1kDQBx3LN"
   },
   "source": [
    "# Training\n",
    "\n",
    "-   `python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --direction BtoA`\n",
    "\n",
    "Change the `--dataroot` and `--name` to your own dataset's path and model's name. Use `--gpu_ids 0,1,..` to train on multiple GPUs and `--batch_size` to change the batch size. Add `--direction BtoA` if you want to train a model to transfrom from class B to A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0sp7TCT2x9dB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 1                             \n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/dataset_for_GAN    \t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: -1                            \t[default: 1]\n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: cycle_gan]\n",
      "                 n_epochs: 100                           \n",
      "           n_epochs_decay: 100                           \n",
      "               n_layers_D: 3                             \n",
      "                     name: dataset_for_GAN_pix2pix       \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: resize_and_crop               \n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 350\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "[Network D] Total number of parameters : 2.769 M\n",
      "-----------------------------------------------\n",
      "create web directory ./checkpoints/dataset_for_GAN_pix2pix/web...\n",
      "/home/omerfarukaydin/anaconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:182: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 1, iters: 100, time: 0.022, data: 0.030) G_GAN: 1.481 G_L1: 25.720 D_real: 0.851 D_fake: 0.242 \n",
      "(epoch: 1, iters: 200, time: 0.022, data: 0.000) G_GAN: 2.065 G_L1: 28.117 D_real: 0.118 D_fake: 0.402 \n",
      "(epoch: 1, iters: 300, time: 0.022, data: 0.000) G_GAN: 2.515 G_L1: 30.575 D_real: 0.777 D_fake: 0.551 \n",
      "End of epoch 1 / 200 \t Time Taken: 5 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 2, iters: 50, time: 0.051, data: 0.001) G_GAN: 5.660 G_L1: 30.345 D_real: 0.030 D_fake: 1.714 \n",
      "(epoch: 2, iters: 150, time: 0.022, data: 0.001) G_GAN: 2.591 G_L1: 29.153 D_real: 0.089 D_fake: 0.166 \n",
      "(epoch: 2, iters: 250, time: 0.021, data: 0.001) G_GAN: 2.527 G_L1: 26.165 D_real: 0.200 D_fake: 0.128 \n",
      "(epoch: 2, iters: 350, time: 0.022, data: 0.000) G_GAN: 0.790 G_L1: 38.733 D_real: 1.226 D_fake: 0.731 \n",
      "End of epoch 2 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 3, iters: 100, time: 0.047, data: 0.037) G_GAN: 1.948 G_L1: 25.328 D_real: 0.574 D_fake: 0.469 \n",
      "(epoch: 3, iters: 200, time: 0.020, data: 0.001) G_GAN: 1.616 G_L1: 26.549 D_real: 0.334 D_fake: 0.223 \n",
      "(epoch: 3, iters: 300, time: 0.023, data: 0.001) G_GAN: 2.127 G_L1: 27.965 D_real: 1.633 D_fake: 0.035 \n",
      "End of epoch 3 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 4, iters: 50, time: 0.021, data: 0.001) G_GAN: 1.867 G_L1: 27.872 D_real: 1.286 D_fake: 0.037 \n",
      "(epoch: 4, iters: 150, time: 0.048, data: 0.000) G_GAN: 2.949 G_L1: 29.766 D_real: 0.058 D_fake: 0.336 \n",
      "(epoch: 4, iters: 250, time: 0.022, data: 0.001) G_GAN: 1.746 G_L1: 29.369 D_real: 0.160 D_fake: 0.401 \n",
      "(epoch: 4, iters: 350, time: 0.022, data: 0.000) G_GAN: 1.569 G_L1: 30.053 D_real: 0.240 D_fake: 0.274 \n",
      "End of epoch 4 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 5, iters: 100, time: 0.021, data: 0.034) G_GAN: 0.961 G_L1: 31.136 D_real: 0.008 D_fake: 1.879 \n",
      "(epoch: 5, iters: 200, time: 0.048, data: 0.000) G_GAN: 0.642 G_L1: 27.211 D_real: 2.502 D_fake: 0.104 \n",
      "(epoch: 5, iters: 300, time: 0.022, data: 0.000) G_GAN: 2.589 G_L1: 29.395 D_real: 0.005 D_fake: 2.079 \n",
      "saving the model at the end of epoch 5, iters 1750\n",
      "End of epoch 5 / 200 \t Time Taken: 5 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 6, iters: 50, time: 0.022, data: 0.000) G_GAN: 1.245 G_L1: 26.606 D_real: 0.109 D_fake: 0.885 \n",
      "(epoch: 6, iters: 150, time: 0.022, data: 0.001) G_GAN: 2.073 G_L1: 29.150 D_real: 0.074 D_fake: 0.276 \n",
      "(epoch: 6, iters: 250, time: 0.050, data: 0.000) G_GAN: 1.732 G_L1: 31.901 D_real: 1.510 D_fake: 0.051 \n",
      "(epoch: 6, iters: 350, time: 0.021, data: 0.001) G_GAN: 1.533 G_L1: 24.079 D_real: 1.843 D_fake: 0.033 \n",
      "End of epoch 6 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 7, iters: 100, time: 0.022, data: 0.041) G_GAN: 1.363 G_L1: 27.505 D_real: 1.508 D_fake: 0.062 \n",
      "(epoch: 7, iters: 200, time: 0.022, data: 0.000) G_GAN: 2.012 G_L1: 27.798 D_real: 0.468 D_fake: 0.131 \n",
      "(epoch: 7, iters: 300, time: 0.050, data: 0.000) G_GAN: 2.450 G_L1: 28.850 D_real: 0.134 D_fake: 0.128 \n",
      "End of epoch 7 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 8, iters: 50, time: 0.020, data: 0.001) G_GAN: 1.194 G_L1: 29.939 D_real: 0.226 D_fake: 0.535 \n",
      "(epoch: 8, iters: 150, time: 0.021, data: 0.000) G_GAN: 1.682 G_L1: 31.165 D_real: 0.376 D_fake: 0.229 \n",
      "(epoch: 8, iters: 250, time: 0.021, data: 0.000) G_GAN: 1.353 G_L1: 27.508 D_real: 0.525 D_fake: 0.226 \n",
      "(epoch: 8, iters: 350, time: 0.050, data: 0.000) G_GAN: 2.397 G_L1: 27.487 D_real: 1.404 D_fake: 0.045 \n",
      "End of epoch 8 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 9, iters: 100, time: 0.021, data: 0.041) G_GAN: 2.474 G_L1: 27.504 D_real: 0.037 D_fake: 0.455 \n",
      "(epoch: 9, iters: 200, time: 0.021, data: 0.000) G_GAN: 1.529 G_L1: 28.628 D_real: 0.089 D_fake: 0.222 \n",
      "(epoch: 9, iters: 300, time: 0.021, data: 0.000) G_GAN: 1.358 G_L1: 30.881 D_real: 0.087 D_fake: 0.867 \n",
      "End of epoch 9 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 10, iters: 50, time: 0.050, data: 0.000) G_GAN: 2.030 G_L1: 31.482 D_real: 0.103 D_fake: 0.699 \n",
      "(epoch: 10, iters: 150, time: 0.021, data: 0.001) G_GAN: 1.931 G_L1: 32.602 D_real: 0.133 D_fake: 0.408 \n",
      "(epoch: 10, iters: 250, time: 0.021, data: 0.000) G_GAN: 0.745 G_L1: 31.972 D_real: 0.005 D_fake: 3.088 \n",
      "(epoch: 10, iters: 350, time: 0.021, data: 0.000) G_GAN: 1.634 G_L1: 27.704 D_real: 0.996 D_fake: 0.091 \n",
      "saving the model at the end of epoch 10, iters 3500\n",
      "End of epoch 10 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 11, iters: 100, time: 0.051, data: 0.052) G_GAN: 1.452 G_L1: 29.670 D_real: 1.126 D_fake: 0.355 \n",
      "(epoch: 11, iters: 200, time: 0.021, data: 0.000) G_GAN: 2.593 G_L1: 26.058 D_real: 0.146 D_fake: 0.116 \n",
      "(epoch: 11, iters: 300, time: 0.021, data: 0.001) G_GAN: 2.259 G_L1: 28.290 D_real: 0.168 D_fake: 0.249 \n",
      "End of epoch 11 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 12, iters: 50, time: 0.021, data: 0.000) G_GAN: 2.277 G_L1: 31.076 D_real: 0.239 D_fake: 0.190 \n",
      "(epoch: 12, iters: 150, time: 0.051, data: 0.000) G_GAN: 1.014 G_L1: 30.402 D_real: 0.432 D_fake: 0.465 \n",
      "(epoch: 12, iters: 250, time: 0.021, data: 0.000) G_GAN: 1.507 G_L1: 28.727 D_real: 0.615 D_fake: 0.173 \n",
      "(epoch: 12, iters: 350, time: 0.021, data: 0.001) G_GAN: 1.708 G_L1: 30.025 D_real: 0.163 D_fake: 2.327 \n",
      "End of epoch 12 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 13, iters: 100, time: 0.021, data: 0.051) G_GAN: 1.798 G_L1: 31.724 D_real: 0.118 D_fake: 0.977 \n",
      "(epoch: 13, iters: 200, time: 0.051, data: 0.000) G_GAN: 1.906 G_L1: 28.188 D_real: 0.094 D_fake: 0.391 \n",
      "(epoch: 13, iters: 300, time: 0.021, data: 0.001) G_GAN: 1.664 G_L1: 27.461 D_real: 0.712 D_fake: 0.196 \n",
      "End of epoch 13 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 14, iters: 50, time: 0.021, data: 0.000) G_GAN: 1.617 G_L1: 27.496 D_real: 0.087 D_fake: 0.292 \n",
      "(epoch: 14, iters: 150, time: 0.021, data: 0.000) G_GAN: 1.871 G_L1: 27.477 D_real: 0.135 D_fake: 0.651 \n",
      "(epoch: 14, iters: 250, time: 0.052, data: 0.000) G_GAN: 1.637 G_L1: 28.805 D_real: 2.123 D_fake: 0.111 \n",
      "(epoch: 14, iters: 350, time: 0.021, data: 0.000) G_GAN: 0.924 G_L1: 31.659 D_real: 0.074 D_fake: 2.570 \n",
      "End of epoch 14 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 15, iters: 100, time: 0.021, data: 0.040) G_GAN: 1.347 G_L1: 29.189 D_real: 0.236 D_fake: 0.660 \n",
      "saving the latest model (epoch 15, total_iters 5000)\n",
      "(epoch: 15, iters: 200, time: 0.021, data: 0.001) G_GAN: 1.478 G_L1: 22.260 D_real: 1.060 D_fake: 0.131 \n",
      "(epoch: 15, iters: 300, time: 0.053, data: 0.001) G_GAN: 2.476 G_L1: 26.142 D_real: 0.220 D_fake: 0.079 \n",
      "saving the model at the end of epoch 15, iters 5250\n",
      "End of epoch 15 / 200 \t Time Taken: 5 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 16, iters: 50, time: 0.021, data: 0.000) G_GAN: 1.225 G_L1: 29.121 D_real: 0.079 D_fake: 0.964 \n",
      "(epoch: 16, iters: 150, time: 0.021, data: 0.000) G_GAN: 2.798 G_L1: 28.033 D_real: 0.505 D_fake: 0.074 \n",
      "(epoch: 16, iters: 250, time: 0.021, data: 0.000) G_GAN: 1.815 G_L1: 27.562 D_real: 0.319 D_fake: 0.151 \n",
      "(epoch: 16, iters: 350, time: 0.054, data: 0.000) G_GAN: 1.756 G_L1: 25.864 D_real: 0.221 D_fake: 0.165 \n",
      "End of epoch 16 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 17, iters: 100, time: 0.020, data: 0.045) G_GAN: 1.946 G_L1: 29.659 D_real: 0.022 D_fake: 0.621 \n",
      "(epoch: 17, iters: 200, time: 0.021, data: 0.001) G_GAN: 1.773 G_L1: 31.888 D_real: 0.007 D_fake: 1.273 \n",
      "(epoch: 17, iters: 300, time: 0.021, data: 0.000) G_GAN: 1.726 G_L1: 26.739 D_real: 0.201 D_fake: 0.083 \n",
      "End of epoch 17 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 18, iters: 50, time: 0.053, data: 0.000) G_GAN: 0.760 G_L1: 30.203 D_real: 0.402 D_fake: 1.195 \n",
      "(epoch: 18, iters: 150, time: 0.021, data: 0.001) G_GAN: 1.321 G_L1: 23.729 D_real: 1.522 D_fake: 0.083 \n",
      "(epoch: 18, iters: 250, time: 0.021, data: 0.000) G_GAN: 1.418 G_L1: 29.368 D_real: 0.293 D_fake: 0.424 \n",
      "(epoch: 18, iters: 350, time: 0.021, data: 0.000) G_GAN: 0.732 G_L1: 25.557 D_real: 0.531 D_fake: 0.395 \n",
      "End of epoch 18 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 19, iters: 100, time: 0.055, data: 0.044) G_GAN: 0.818 G_L1: 24.730 D_real: 0.422 D_fake: 0.351 \n",
      "(epoch: 19, iters: 200, time: 0.021, data: 0.000) G_GAN: 1.753 G_L1: 31.879 D_real: 0.075 D_fake: 0.631 \n",
      "(epoch: 19, iters: 300, time: 0.021, data: 0.000) G_GAN: 1.410 G_L1: 29.806 D_real: 0.129 D_fake: 0.362 \n",
      "End of epoch 19 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 20, iters: 50, time: 0.021, data: 0.000) G_GAN: 2.233 G_L1: 25.149 D_real: 0.607 D_fake: 0.084 \n",
      "(epoch: 20, iters: 150, time: 0.055, data: 0.000) G_GAN: 2.136 G_L1: 28.553 D_real: 0.014 D_fake: 0.251 \n",
      "(epoch: 20, iters: 250, time: 0.021, data: 0.001) G_GAN: 2.474 G_L1: 30.404 D_real: 0.004 D_fake: 1.664 \n",
      "(epoch: 20, iters: 350, time: 0.021, data: 0.000) G_GAN: 1.925 G_L1: 26.605 D_real: 0.148 D_fake: 0.352 \n",
      "saving the model at the end of epoch 20, iters 7000\n",
      "End of epoch 20 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 21, iters: 100, time: 0.021, data: 0.056) G_GAN: 1.942 G_L1: 29.481 D_real: 0.123 D_fake: 0.464 \n",
      "(epoch: 21, iters: 200, time: 0.054, data: 0.000) G_GAN: 1.244 G_L1: 28.063 D_real: 0.435 D_fake: 0.295 \n",
      "(epoch: 21, iters: 300, time: 0.021, data: 0.000) G_GAN: 1.415 G_L1: 30.106 D_real: 0.306 D_fake: 0.751 \n",
      "End of epoch 21 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 22, iters: 50, time: 0.021, data: 0.000) G_GAN: 5.068 G_L1: 25.116 D_real: 0.001 D_fake: 3.275 \n",
      "(epoch: 22, iters: 150, time: 0.021, data: 0.001) G_GAN: 1.760 G_L1: 29.735 D_real: 0.090 D_fake: 1.713 \n",
      "(epoch: 22, iters: 250, time: 0.055, data: 0.000) G_GAN: 2.275 G_L1: 31.925 D_real: 0.147 D_fake: 1.257 \n",
      "(epoch: 22, iters: 350, time: 0.021, data: 0.000) G_GAN: 1.180 G_L1: 26.879 D_real: 0.469 D_fake: 0.390 \n",
      "End of epoch 22 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 23, iters: 100, time: 0.021, data: 0.037) G_GAN: 1.724 G_L1: 26.130 D_real: 0.391 D_fake: 0.147 \n",
      "(epoch: 23, iters: 200, time: 0.021, data: 0.000) G_GAN: 0.769 G_L1: 26.050 D_real: 1.665 D_fake: 0.281 \n",
      "(epoch: 23, iters: 300, time: 0.055, data: 0.001) G_GAN: 1.771 G_L1: 30.918 D_real: 0.248 D_fake: 0.891 \n",
      "End of epoch 23 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 24, iters: 50, time: 0.021, data: 0.001) G_GAN: 1.418 G_L1: 30.678 D_real: 0.101 D_fake: 0.336 \n",
      "(epoch: 24, iters: 150, time: 0.021, data: 0.000) G_GAN: 1.652 G_L1: 27.403 D_real: 0.306 D_fake: 0.237 \n",
      "(epoch: 24, iters: 250, time: 0.021, data: 0.000) G_GAN: 1.582 G_L1: 27.248 D_real: 0.280 D_fake: 0.159 \n",
      "(epoch: 24, iters: 350, time: 0.057, data: 0.000) G_GAN: 1.875 G_L1: 29.172 D_real: 0.509 D_fake: 0.225 \n",
      "End of epoch 24 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 25, iters: 100, time: 0.021, data: 0.034) G_GAN: 1.475 G_L1: 29.151 D_real: 0.160 D_fake: 0.446 \n",
      "(epoch: 25, iters: 200, time: 0.020, data: 0.000) G_GAN: 2.320 G_L1: 28.864 D_real: 0.124 D_fake: 0.240 \n",
      "(epoch: 25, iters: 300, time: 0.021, data: 0.000) G_GAN: 1.332 G_L1: 31.289 D_real: 0.690 D_fake: 0.112 \n",
      "saving the model at the end of epoch 25, iters 8750\n",
      "End of epoch 25 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 26, iters: 50, time: 0.056, data: 0.000) G_GAN: 0.825 G_L1: 32.853 D_real: 0.767 D_fake: 0.474 \n",
      "(epoch: 26, iters: 150, time: 0.021, data: 0.000) G_GAN: 2.556 G_L1: 31.798 D_real: 0.090 D_fake: 1.870 \n",
      "(epoch: 26, iters: 250, time: 0.021, data: 0.000) G_GAN: 0.871 G_L1: 26.062 D_real: 0.465 D_fake: 1.811 \n",
      "(epoch: 26, iters: 350, time: 0.021, data: 0.000) G_GAN: 1.203 G_L1: 28.998 D_real: 0.374 D_fake: 0.232 \n",
      "End of epoch 26 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 27, iters: 100, time: 0.058, data: 0.055) G_GAN: 1.617 G_L1: 25.659 D_real: 0.089 D_fake: 0.203 \n",
      "(epoch: 27, iters: 200, time: 0.021, data: 0.001) G_GAN: 1.769 G_L1: 29.698 D_real: 0.289 D_fake: 0.668 \n",
      "(epoch: 27, iters: 300, time: 0.021, data: 0.000) G_GAN: 1.628 G_L1: 26.249 D_real: 0.071 D_fake: 0.459 \n",
      "End of epoch 27 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 28, iters: 50, time: 0.021, data: 0.000) G_GAN: 1.798 G_L1: 29.418 D_real: 0.111 D_fake: 0.238 \n",
      "(epoch: 28, iters: 150, time: 0.058, data: 0.000) G_GAN: 1.700 G_L1: 26.749 D_real: 1.356 D_fake: 0.249 \n",
      "(epoch: 28, iters: 250, time: 0.021, data: 0.000) G_GAN: 1.069 G_L1: 29.037 D_real: 0.010 D_fake: 2.925 \n",
      "(epoch: 28, iters: 350, time: 0.021, data: 0.001) G_GAN: 0.945 G_L1: 29.793 D_real: 0.734 D_fake: 0.290 \n",
      "End of epoch 28 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 29, iters: 100, time: 0.021, data: 0.039) G_GAN: 2.027 G_L1: 30.711 D_real: 0.176 D_fake: 0.135 \n",
      "(epoch: 29, iters: 200, time: 0.058, data: 0.000) G_GAN: 2.412 G_L1: 29.068 D_real: 0.488 D_fake: 0.091 \n",
      "saving the latest model (epoch 29, total_iters 10000)\n",
      "(epoch: 29, iters: 300, time: 0.021, data: 0.001) G_GAN: 1.552 G_L1: 32.739 D_real: 0.447 D_fake: 1.434 \n",
      "End of epoch 29 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 30, iters: 50, time: 0.021, data: 0.000) G_GAN: 0.587 G_L1: 24.491 D_real: 1.477 D_fake: 0.249 \n",
      "(epoch: 30, iters: 150, time: 0.020, data: 0.000) G_GAN: 1.326 G_L1: 26.457 D_real: 0.381 D_fake: 0.204 \n",
      "(epoch: 30, iters: 250, time: 0.143, data: 0.000) G_GAN: 1.887 G_L1: 29.134 D_real: 0.542 D_fake: 0.212 \n",
      "(epoch: 30, iters: 350, time: 0.021, data: 0.001) G_GAN: 1.911 G_L1: 30.198 D_real: 0.039 D_fake: 0.519 \n",
      "saving the model at the end of epoch 30, iters 10500\n",
      "End of epoch 30 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 31, iters: 100, time: 0.021, data: 0.055) G_GAN: 1.480 G_L1: 28.750 D_real: 0.284 D_fake: 0.586 \n",
      "(epoch: 31, iters: 200, time: 0.021, data: 0.000) G_GAN: 1.707 G_L1: 27.569 D_real: 0.125 D_fake: 0.529 \n",
      "(epoch: 31, iters: 300, time: 0.058, data: 0.000) G_GAN: 1.975 G_L1: 32.016 D_real: 0.037 D_fake: 1.892 \n",
      "End of epoch 31 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 32, iters: 50, time: 0.021, data: 0.001) G_GAN: 2.814 G_L1: 29.766 D_real: 0.009 D_fake: 1.951 \n",
      "(epoch: 32, iters: 150, time: 0.021, data: 0.000) G_GAN: 1.683 G_L1: 28.613 D_real: 0.069 D_fake: 0.990 \n",
      "(epoch: 32, iters: 250, time: 0.021, data: 0.000) G_GAN: 1.913 G_L1: 30.061 D_real: 0.474 D_fake: 0.409 \n",
      "(epoch: 32, iters: 350, time: 0.059, data: 0.000) G_GAN: 2.400 G_L1: 29.625 D_real: 0.331 D_fake: 1.129 \n",
      "End of epoch 32 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 33, iters: 100, time: 0.021, data: 0.033) G_GAN: 0.559 G_L1: 29.287 D_real: 1.371 D_fake: 0.334 \n",
      "(epoch: 33, iters: 200, time: 0.021, data: 0.000) G_GAN: 1.281 G_L1: 27.632 D_real: 0.571 D_fake: 0.287 \n",
      "(epoch: 33, iters: 300, time: 0.021, data: 0.000) G_GAN: 1.322 G_L1: 26.003 D_real: 0.270 D_fake: 0.428 \n",
      "End of epoch 33 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 34, iters: 50, time: 0.061, data: 0.000) G_GAN: 1.735 G_L1: 29.726 D_real: 0.688 D_fake: 0.231 \n",
      "(epoch: 34, iters: 150, time: 0.021, data: 0.000) G_GAN: 1.548 G_L1: 29.971 D_real: 0.077 D_fake: 0.357 \n",
      "(epoch: 34, iters: 250, time: 0.021, data: 0.001) G_GAN: 2.428 G_L1: 29.636 D_real: 0.076 D_fake: 0.162 \n",
      "(epoch: 34, iters: 350, time: 0.021, data: 0.000) G_GAN: 0.967 G_L1: 27.763 D_real: 1.126 D_fake: 0.683 \n",
      "End of epoch 34 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 35, iters: 100, time: 0.062, data: 0.038) G_GAN: 1.418 G_L1: 26.568 D_real: 0.317 D_fake: 0.354 \n",
      "(epoch: 35, iters: 200, time: 0.021, data: 0.000) G_GAN: 2.046 G_L1: 25.426 D_real: 0.537 D_fake: 0.098 \n",
      "(epoch: 35, iters: 300, time: 0.021, data: 0.000) G_GAN: 0.949 G_L1: 28.401 D_real: 0.542 D_fake: 0.655 \n",
      "saving the model at the end of epoch 35, iters 12250\n",
      "End of epoch 35 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 36, iters: 50, time: 0.021, data: 0.000) G_GAN: 1.088 G_L1: 26.018 D_real: 1.030 D_fake: 0.128 \n",
      "(epoch: 36, iters: 150, time: 0.061, data: 0.000) G_GAN: 0.526 G_L1: 24.573 D_real: 2.044 D_fake: 0.148 \n",
      "(epoch: 36, iters: 250, time: 0.021, data: 0.001) G_GAN: 2.364 G_L1: 31.267 D_real: 0.011 D_fake: 0.275 \n",
      "(epoch: 36, iters: 350, time: 0.021, data: 0.001) G_GAN: 0.917 G_L1: 27.385 D_real: 0.265 D_fake: 0.524 \n",
      "End of epoch 36 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 37, iters: 100, time: 0.021, data: 0.036) G_GAN: 1.086 G_L1: 28.116 D_real: 0.769 D_fake: 0.754 \n",
      "(epoch: 37, iters: 200, time: 0.062, data: 0.000) G_GAN: 1.841 G_L1: 28.898 D_real: 0.315 D_fake: 0.294 \n",
      "(epoch: 37, iters: 300, time: 0.021, data: 0.000) G_GAN: 1.715 G_L1: 30.994 D_real: 0.056 D_fake: 0.366 \n",
      "End of epoch 37 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 38, iters: 50, time: 0.020, data: 0.001) G_GAN: 1.612 G_L1: 29.320 D_real: 0.113 D_fake: 0.410 \n",
      "(epoch: 38, iters: 150, time: 0.021, data: 0.000) G_GAN: 1.613 G_L1: 27.243 D_real: 0.211 D_fake: 0.535 \n",
      "(epoch: 38, iters: 250, time: 0.062, data: 0.001) G_GAN: 1.381 G_L1: 31.838 D_real: 0.111 D_fake: 0.924 \n",
      "(epoch: 38, iters: 350, time: 0.021, data: 0.000) G_GAN: 1.313 G_L1: 32.940 D_real: 0.557 D_fake: 0.444 \n",
      "End of epoch 38 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 39, iters: 100, time: 0.020, data: 0.043) G_GAN: 1.383 G_L1: 29.601 D_real: 0.828 D_fake: 0.221 \n",
      "(epoch: 39, iters: 200, time: 0.021, data: 0.000) G_GAN: 2.105 G_L1: 28.988 D_real: 0.121 D_fake: 1.066 \n",
      "(epoch: 39, iters: 300, time: 0.063, data: 0.000) G_GAN: 2.104 G_L1: 28.945 D_real: 0.130 D_fake: 0.241 \n",
      "End of epoch 39 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 40, iters: 50, time: 0.021, data: 0.001) G_GAN: 1.485 G_L1: 26.551 D_real: 0.103 D_fake: 1.049 \n",
      "(epoch: 40, iters: 150, time: 0.021, data: 0.000) G_GAN: 1.342 G_L1: 30.065 D_real: 0.048 D_fake: 0.443 \n",
      "(epoch: 40, iters: 250, time: 0.021, data: 0.000) G_GAN: 1.769 G_L1: 28.134 D_real: 0.577 D_fake: 0.137 \n",
      "(epoch: 40, iters: 350, time: 0.062, data: 0.000) G_GAN: 2.162 G_L1: 29.662 D_real: 0.231 D_fake: 1.284 \n",
      "saving the model at the end of epoch 40, iters 14000\n",
      "End of epoch 40 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 41, iters: 100, time: 0.021, data: 0.056) G_GAN: 1.883 G_L1: 30.490 D_real: 0.088 D_fake: 0.311 \n",
      "(epoch: 41, iters: 200, time: 0.020, data: 0.000) G_GAN: 1.878 G_L1: 31.450 D_real: 0.389 D_fake: 0.218 \n",
      "(epoch: 41, iters: 300, time: 0.021, data: 0.000) G_GAN: 1.553 G_L1: 27.207 D_real: 0.148 D_fake: 0.372 \n",
      "End of epoch 41 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 42, iters: 50, time: 0.069, data: 0.000) G_GAN: 1.823 G_L1: 30.192 D_real: 0.304 D_fake: 0.171 \n",
      "(epoch: 42, iters: 150, time: 0.021, data: 0.001) G_GAN: 1.779 G_L1: 25.893 D_real: 1.882 D_fake: 0.041 \n",
      "(epoch: 42, iters: 250, time: 0.021, data: 0.000) G_GAN: 1.878 G_L1: 25.871 D_real: 0.139 D_fake: 0.539 \n",
      "(epoch: 42, iters: 350, time: 0.021, data: 0.000) G_GAN: 0.467 G_L1: 28.885 D_real: 1.085 D_fake: 0.331 \n",
      "End of epoch 42 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 43, iters: 100, time: 0.064, data: 0.035) G_GAN: 0.782 G_L1: 28.727 D_real: 0.618 D_fake: 0.290 \n",
      "(epoch: 43, iters: 200, time: 0.021, data: 0.001) G_GAN: 1.951 G_L1: 25.563 D_real: 0.528 D_fake: 0.157 \n",
      "(epoch: 43, iters: 300, time: 0.021, data: 0.001) G_GAN: 1.069 G_L1: 25.126 D_real: 0.752 D_fake: 0.208 \n",
      "saving the latest model (epoch 43, total_iters 15000)\n",
      "End of epoch 43 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 44, iters: 50, time: 0.021, data: 0.001) G_GAN: 1.945 G_L1: 25.947 D_real: 0.382 D_fake: 0.099 \n",
      "(epoch: 44, iters: 150, time: 0.065, data: 0.000) G_GAN: 1.961 G_L1: 29.739 D_real: 0.026 D_fake: 0.980 \n",
      "(epoch: 44, iters: 250, time: 0.020, data: 0.001) G_GAN: 0.638 G_L1: 25.687 D_real: 1.308 D_fake: 0.241 \n",
      "(epoch: 44, iters: 350, time: 0.021, data: 0.000) G_GAN: 1.267 G_L1: 25.251 D_real: 2.869 D_fake: 0.157 \n",
      "End of epoch 44 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 45, iters: 100, time: 0.021, data: 0.040) G_GAN: 2.152 G_L1: 30.810 D_real: 0.452 D_fake: 0.088 \n",
      "(epoch: 45, iters: 200, time: 0.066, data: 0.000) G_GAN: 1.324 G_L1: 30.375 D_real: 0.117 D_fake: 0.508 \n",
      "(epoch: 45, iters: 300, time: 0.021, data: 0.001) G_GAN: 1.432 G_L1: 28.396 D_real: 0.420 D_fake: 0.202 \n",
      "saving the model at the end of epoch 45, iters 15750\n",
      "End of epoch 45 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 46, iters: 50, time: 0.020, data: 0.000) G_GAN: 0.876 G_L1: 28.613 D_real: 2.376 D_fake: 0.106 \n",
      "(epoch: 46, iters: 150, time: 0.020, data: 0.000) G_GAN: 1.991 G_L1: 27.631 D_real: 0.160 D_fake: 0.679 \n",
      "(epoch: 46, iters: 250, time: 0.065, data: 0.001) G_GAN: 1.834 G_L1: 34.423 D_real: 0.316 D_fake: 0.217 \n",
      "(epoch: 46, iters: 350, time: 0.021, data: 0.001) G_GAN: 1.752 G_L1: 28.633 D_real: 0.304 D_fake: 0.393 \n",
      "End of epoch 46 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 47, iters: 100, time: 0.021, data: 0.035) G_GAN: 0.933 G_L1: 28.651 D_real: 0.899 D_fake: 0.283 \n",
      "(epoch: 47, iters: 200, time: 0.021, data: 0.000) G_GAN: 1.560 G_L1: 29.257 D_real: 0.284 D_fake: 0.434 \n",
      "(epoch: 47, iters: 300, time: 0.067, data: 0.001) G_GAN: 1.793 G_L1: 26.588 D_real: 1.510 D_fake: 0.059 \n",
      "End of epoch 47 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 48, iters: 50, time: 0.021, data: 0.000) G_GAN: 0.615 G_L1: 28.661 D_real: 0.794 D_fake: 0.265 \n",
      "(epoch: 48, iters: 150, time: 0.021, data: 0.000) G_GAN: 1.723 G_L1: 29.853 D_real: 0.074 D_fake: 0.881 \n",
      "(epoch: 48, iters: 250, time: 0.021, data: 0.000) G_GAN: 1.758 G_L1: 29.641 D_real: 0.018 D_fake: 0.787 \n",
      "(epoch: 48, iters: 350, time: 0.067, data: 0.000) G_GAN: 2.239 G_L1: 29.929 D_real: 0.399 D_fake: 0.084 \n",
      "End of epoch 48 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 49, iters: 100, time: 0.021, data: 0.041) G_GAN: 1.361 G_L1: 26.817 D_real: 0.599 D_fake: 0.249 \n",
      "(epoch: 49, iters: 200, time: 0.021, data: 0.000) G_GAN: 2.074 G_L1: 33.035 D_real: 0.240 D_fake: 0.427 \n",
      "(epoch: 49, iters: 300, time: 0.021, data: 0.001) G_GAN: 1.047 G_L1: 24.417 D_real: 2.422 D_fake: 0.163 \n",
      "End of epoch 49 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 50, iters: 50, time: 0.067, data: 0.000) G_GAN: 1.509 G_L1: 28.181 D_real: 0.585 D_fake: 0.216 \n",
      "(epoch: 50, iters: 150, time: 0.021, data: 0.001) G_GAN: 1.111 G_L1: 26.256 D_real: 0.482 D_fake: 0.325 \n",
      "(epoch: 50, iters: 250, time: 0.021, data: 0.000) G_GAN: 0.940 G_L1: 29.724 D_real: 0.973 D_fake: 0.091 \n",
      "(epoch: 50, iters: 350, time: 0.021, data: 0.000) G_GAN: 1.388 G_L1: 29.094 D_real: 1.490 D_fake: 0.145 \n",
      "saving the model at the end of epoch 50, iters 17500\n",
      "End of epoch 50 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 51, iters: 100, time: 0.069, data: 0.058) G_GAN: 1.621 G_L1: 31.124 D_real: 0.086 D_fake: 0.855 \n",
      "(epoch: 51, iters: 200, time: 0.021, data: 0.001) G_GAN: 2.015 G_L1: 31.367 D_real: 0.291 D_fake: 1.293 \n",
      "(epoch: 51, iters: 300, time: 0.021, data: 0.000) G_GAN: 2.155 G_L1: 25.644 D_real: 0.013 D_fake: 0.520 \n",
      "End of epoch 51 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 52, iters: 50, time: 0.021, data: 0.000) G_GAN: 2.681 G_L1: 28.555 D_real: 0.470 D_fake: 0.065 \n",
      "(epoch: 52, iters: 150, time: 0.068, data: 0.000) G_GAN: 1.387 G_L1: 25.733 D_real: 0.099 D_fake: 0.255 \n",
      "(epoch: 52, iters: 250, time: 0.021, data: 0.001) G_GAN: 1.326 G_L1: 26.638 D_real: 2.376 D_fake: 0.111 \n",
      "(epoch: 52, iters: 350, time: 0.021, data: 0.000) G_GAN: 2.019 G_L1: 28.625 D_real: 0.018 D_fake: 0.887 \n",
      "End of epoch 52 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 53, iters: 100, time: 0.021, data: 0.037) G_GAN: 2.064 G_L1: 26.352 D_real: 0.243 D_fake: 0.398 \n",
      "(epoch: 53, iters: 200, time: 0.067, data: 0.000) G_GAN: 1.915 G_L1: 28.321 D_real: 0.116 D_fake: 0.776 \n",
      "(epoch: 53, iters: 300, time: 0.021, data: 0.001) G_GAN: 1.668 G_L1: 28.649 D_real: 0.461 D_fake: 0.310 \n",
      "End of epoch 53 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 54, iters: 50, time: 0.021, data: 0.000) G_GAN: 0.421 G_L1: 28.688 D_real: 2.391 D_fake: 0.185 \n",
      "(epoch: 54, iters: 150, time: 0.021, data: 0.000) G_GAN: 1.913 G_L1: 28.587 D_real: 0.163 D_fake: 0.466 \n",
      "(epoch: 54, iters: 250, time: 0.069, data: 0.000) G_GAN: 0.545 G_L1: 24.612 D_real: 2.140 D_fake: 0.240 \n",
      "(epoch: 54, iters: 350, time: 0.020, data: 0.000) G_GAN: 1.918 G_L1: 28.228 D_real: 0.133 D_fake: 0.301 \n",
      "End of epoch 54 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 55, iters: 100, time: 0.020, data: 0.034) G_GAN: 2.071 G_L1: 34.643 D_real: 0.303 D_fake: 0.270 \n",
      "(epoch: 55, iters: 200, time: 0.021, data: 0.000) G_GAN: 1.841 G_L1: 30.263 D_real: 0.172 D_fake: 0.451 \n",
      "(epoch: 55, iters: 300, time: 0.069, data: 0.001) G_GAN: 1.560 G_L1: 27.472 D_real: 0.303 D_fake: 0.890 \n",
      "saving the model at the end of epoch 55, iters 19250\n",
      "End of epoch 55 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 56, iters: 50, time: 0.021, data: 0.001) G_GAN: 2.230 G_L1: 30.568 D_real: 0.063 D_fake: 0.435 \n",
      "(epoch: 56, iters: 150, time: 0.021, data: 0.000) G_GAN: 1.586 G_L1: 31.145 D_real: 0.936 D_fake: 0.155 \n",
      "(epoch: 56, iters: 250, time: 0.021, data: 0.000) G_GAN: 1.387 G_L1: 29.695 D_real: 1.100 D_fake: 0.085 \n",
      "(epoch: 56, iters: 350, time: 0.069, data: 0.000) G_GAN: 2.086 G_L1: 28.173 D_real: 0.254 D_fake: 0.202 \n",
      "End of epoch 56 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 57, iters: 100, time: 0.021, data: 0.038) G_GAN: 1.473 G_L1: 26.709 D_real: 0.734 D_fake: 0.170 \n",
      "(epoch: 57, iters: 200, time: 0.021, data: 0.000) G_GAN: 1.151 G_L1: 27.679 D_real: 1.486 D_fake: 0.177 \n",
      "(epoch: 57, iters: 300, time: 0.020, data: 0.000) G_GAN: 1.173 G_L1: 23.943 D_real: 0.463 D_fake: 0.338 \n",
      "End of epoch 57 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 58, iters: 50, time: 0.070, data: 0.000) G_GAN: 2.692 G_L1: 30.201 D_real: 0.416 D_fake: 0.141 \n",
      "saving the latest model (epoch 58, total_iters 20000)\n",
      "(epoch: 58, iters: 150, time: 0.020, data: 0.001) G_GAN: 2.035 G_L1: 28.292 D_real: 0.170 D_fake: 0.269 \n",
      "(epoch: 58, iters: 250, time: 0.021, data: 0.000) G_GAN: 1.413 G_L1: 30.059 D_real: 0.256 D_fake: 0.773 \n",
      "(epoch: 58, iters: 350, time: 0.021, data: 0.000) G_GAN: 1.645 G_L1: 25.293 D_real: 0.309 D_fake: 0.404 \n",
      "End of epoch 58 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 59, iters: 100, time: 0.075, data: 0.049) G_GAN: 1.420 G_L1: 26.073 D_real: 0.258 D_fake: 0.483 \n",
      "(epoch: 59, iters: 200, time: 0.021, data: 0.001) G_GAN: 0.444 G_L1: 28.994 D_real: 2.057 D_fake: 0.107 \n",
      "(epoch: 59, iters: 300, time: 0.021, data: 0.000) G_GAN: 1.263 G_L1: 28.311 D_real: 1.409 D_fake: 0.280 \n",
      "End of epoch 59 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 60, iters: 50, time: 0.020, data: 0.000) G_GAN: 1.608 G_L1: 26.902 D_real: 0.546 D_fake: 0.692 \n",
      "(epoch: 60, iters: 150, time: 0.072, data: 0.000) G_GAN: 1.484 G_L1: 26.006 D_real: 0.247 D_fake: 0.727 \n",
      "(epoch: 60, iters: 250, time: 0.021, data: 0.000) G_GAN: 1.804 G_L1: 30.437 D_real: 0.791 D_fake: 1.094 \n",
      "(epoch: 60, iters: 350, time: 0.021, data: 0.000) G_GAN: 0.941 G_L1: 28.553 D_real: 0.532 D_fake: 0.532 \n",
      "saving the model at the end of epoch 60, iters 21000\n",
      "End of epoch 60 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 61, iters: 100, time: 0.022, data: 0.058) G_GAN: 1.606 G_L1: 23.877 D_real: 1.742 D_fake: 0.124 \n",
      "(epoch: 61, iters: 200, time: 0.073, data: 0.000) G_GAN: 2.050 G_L1: 26.232 D_real: 0.040 D_fake: 0.638 \n",
      "(epoch: 61, iters: 300, time: 0.021, data: 0.001) G_GAN: 0.972 G_L1: 26.911 D_real: 1.220 D_fake: 0.158 \n",
      "End of epoch 61 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 62, iters: 50, time: 0.021, data: 0.000) G_GAN: 0.631 G_L1: 23.248 D_real: 0.896 D_fake: 0.336 \n",
      "(epoch: 62, iters: 150, time: 0.021, data: 0.000) G_GAN: 0.757 G_L1: 29.177 D_real: 2.695 D_fake: 0.078 \n",
      "(epoch: 62, iters: 250, time: 0.072, data: 0.000) G_GAN: 0.454 G_L1: 30.283 D_real: 2.492 D_fake: 0.198 \n",
      "(epoch: 62, iters: 350, time: 0.020, data: 0.001) G_GAN: 1.593 G_L1: 25.595 D_real: 0.684 D_fake: 0.083 \n",
      "End of epoch 62 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 63, iters: 100, time: 0.021, data: 0.038) G_GAN: 1.086 G_L1: 31.774 D_real: 1.333 D_fake: 0.139 \n",
      "(epoch: 63, iters: 200, time: 0.021, data: 0.000) G_GAN: 2.258 G_L1: 22.177 D_real: 0.239 D_fake: 0.095 \n",
      "(epoch: 63, iters: 300, time: 0.072, data: 0.000) G_GAN: 1.916 G_L1: 25.746 D_real: 0.072 D_fake: 1.047 \n",
      "End of epoch 63 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 64, iters: 50, time: 0.021, data: 0.001) G_GAN: 2.064 G_L1: 28.862 D_real: 0.214 D_fake: 1.430 \n",
      "(epoch: 64, iters: 150, time: 0.021, data: 0.001) G_GAN: 1.824 G_L1: 26.051 D_real: 0.196 D_fake: 0.249 \n",
      "(epoch: 64, iters: 250, time: 0.021, data: 0.000) G_GAN: 1.282 G_L1: 27.414 D_real: 0.773 D_fake: 0.359 \n",
      "(epoch: 64, iters: 350, time: 0.073, data: 0.000) G_GAN: 1.144 G_L1: 28.396 D_real: 0.170 D_fake: 0.801 \n",
      "End of epoch 64 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 65, iters: 100, time: 0.021, data: 0.040) G_GAN: 2.274 G_L1: 31.854 D_real: 0.959 D_fake: 1.865 \n",
      "(epoch: 65, iters: 200, time: 0.021, data: 0.000) G_GAN: 1.794 G_L1: 29.805 D_real: 0.358 D_fake: 0.148 \n",
      "(epoch: 65, iters: 300, time: 0.021, data: 0.001) G_GAN: 1.754 G_L1: 30.765 D_real: 0.717 D_fake: 0.120 \n",
      "saving the model at the end of epoch 65, iters 22750\n",
      "End of epoch 65 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 66, iters: 50, time: 0.073, data: 0.000) G_GAN: 1.197 G_L1: 28.733 D_real: 0.931 D_fake: 0.250 \n",
      "(epoch: 66, iters: 150, time: 0.021, data: 0.001) G_GAN: 2.456 G_L1: 27.525 D_real: 0.038 D_fake: 0.823 \n",
      "(epoch: 66, iters: 250, time: 0.021, data: 0.000) G_GAN: 1.360 G_L1: 27.807 D_real: 0.492 D_fake: 0.771 \n",
      "(epoch: 66, iters: 350, time: 0.020, data: 0.001) G_GAN: 1.605 G_L1: 24.739 D_real: 0.593 D_fake: 0.308 \n",
      "End of epoch 66 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 67, iters: 100, time: 0.179, data: 0.034) G_GAN: 2.467 G_L1: 28.943 D_real: 0.024 D_fake: 0.619 \n",
      "(epoch: 67, iters: 200, time: 0.021, data: 0.001) G_GAN: 1.016 G_L1: 30.094 D_real: 0.936 D_fake: 0.449 \n",
      "(epoch: 67, iters: 300, time: 0.021, data: 0.000) G_GAN: 1.561 G_L1: 28.015 D_real: 0.269 D_fake: 0.299 \n",
      "End of epoch 67 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 68, iters: 50, time: 0.020, data: 0.000) G_GAN: 1.230 G_L1: 24.994 D_real: 0.406 D_fake: 0.422 \n",
      "(epoch: 68, iters: 150, time: 0.075, data: 0.000) G_GAN: 1.533 G_L1: 27.386 D_real: 0.147 D_fake: 0.476 \n",
      "(epoch: 68, iters: 250, time: 0.021, data: 0.001) G_GAN: 2.202 G_L1: 29.300 D_real: 0.252 D_fake: 0.432 \n",
      "(epoch: 68, iters: 350, time: 0.021, data: 0.001) G_GAN: 1.890 G_L1: 29.722 D_real: 0.026 D_fake: 0.483 \n",
      "End of epoch 68 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 69, iters: 100, time: 0.021, data: 0.041) G_GAN: 1.066 G_L1: 26.837 D_real: 0.937 D_fake: 0.153 \n",
      "(epoch: 69, iters: 200, time: 0.075, data: 0.001) G_GAN: 2.044 G_L1: 28.117 D_real: 0.103 D_fake: 0.702 \n",
      "(epoch: 69, iters: 300, time: 0.021, data: 0.001) G_GAN: 2.395 G_L1: 29.772 D_real: 0.221 D_fake: 0.409 \n",
      "End of epoch 69 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 70, iters: 50, time: 0.021, data: 0.000) G_GAN: 1.810 G_L1: 26.153 D_real: 0.897 D_fake: 0.125 \n",
      "(epoch: 70, iters: 150, time: 0.021, data: 0.000) G_GAN: 1.556 G_L1: 26.286 D_real: 0.362 D_fake: 0.254 \n",
      "(epoch: 70, iters: 250, time: 0.075, data: 0.000) G_GAN: 1.519 G_L1: 29.340 D_real: 0.321 D_fake: 0.381 \n",
      "(epoch: 70, iters: 350, time: 0.021, data: 0.000) G_GAN: 1.216 G_L1: 28.789 D_real: 1.047 D_fake: 0.178 \n",
      "saving the model at the end of epoch 70, iters 24500\n",
      "End of epoch 70 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 71, iters: 100, time: 0.022, data: 0.057) G_GAN: 1.779 G_L1: 26.872 D_real: 0.131 D_fake: 0.312 \n",
      "(epoch: 71, iters: 200, time: 0.021, data: 0.000) G_GAN: 2.737 G_L1: 30.383 D_real: 0.107 D_fake: 0.216 \n",
      "(epoch: 71, iters: 300, time: 0.081, data: 0.000) G_GAN: 2.167 G_L1: 25.833 D_real: 0.640 D_fake: 0.089 \n",
      "End of epoch 71 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 72, iters: 50, time: 0.021, data: 0.001) G_GAN: 1.496 G_L1: 26.842 D_real: 0.619 D_fake: 0.309 \n",
      "(epoch: 72, iters: 150, time: 0.021, data: 0.000) G_GAN: 1.087 G_L1: 28.916 D_real: 0.466 D_fake: 0.468 \n",
      "saving the latest model (epoch 72, total_iters 25000)\n",
      "(epoch: 72, iters: 250, time: 0.021, data: 0.001) G_GAN: 2.979 G_L1: 29.055 D_real: 0.050 D_fake: 0.564 \n",
      "(epoch: 72, iters: 350, time: 0.076, data: 0.000) G_GAN: 1.725 G_L1: 26.906 D_real: 0.312 D_fake: 0.431 \n",
      "End of epoch 72 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 73, iters: 100, time: 0.021, data: 0.051) G_GAN: 1.944 G_L1: 28.589 D_real: 0.812 D_fake: 0.074 \n",
      "(epoch: 73, iters: 200, time: 0.021, data: 0.000) G_GAN: 0.784 G_L1: 27.133 D_real: 1.676 D_fake: 0.107 \n",
      "(epoch: 73, iters: 300, time: 0.021, data: 0.000) G_GAN: 1.289 G_L1: 23.900 D_real: 1.468 D_fake: 0.168 \n",
      "End of epoch 73 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 74, iters: 50, time: 0.078, data: 0.000) G_GAN: 0.744 G_L1: 29.184 D_real: 1.379 D_fake: 0.228 \n",
      "(epoch: 74, iters: 150, time: 0.021, data: 0.000) G_GAN: 1.838 G_L1: 26.257 D_real: 0.489 D_fake: 0.126 \n",
      "(epoch: 74, iters: 250, time: 0.021, data: 0.001) G_GAN: 2.427 G_L1: 26.237 D_real: 0.609 D_fake: 0.085 \n",
      "(epoch: 74, iters: 350, time: 0.021, data: 0.000) G_GAN: 0.988 G_L1: 22.417 D_real: 1.294 D_fake: 0.119 \n",
      "End of epoch 74 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 75, iters: 100, time: 0.079, data: 0.051) G_GAN: 1.308 G_L1: 27.794 D_real: 1.596 D_fake: 0.152 \n",
      "(epoch: 75, iters: 200, time: 0.021, data: 0.001) G_GAN: 2.169 G_L1: 26.952 D_real: 0.040 D_fake: 1.034 \n",
      "(epoch: 75, iters: 300, time: 0.021, data: 0.000) G_GAN: 2.688 G_L1: 30.599 D_real: 0.252 D_fake: 0.161 \n",
      "saving the model at the end of epoch 75, iters 26250\n",
      "End of epoch 75 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 76, iters: 50, time: 0.021, data: 0.000) G_GAN: 1.850 G_L1: 29.584 D_real: 0.197 D_fake: 0.396 \n",
      "(epoch: 76, iters: 150, time: 0.078, data: 0.000) G_GAN: 1.506 G_L1: 27.280 D_real: 0.727 D_fake: 0.369 \n",
      "(epoch: 76, iters: 250, time: 0.021, data: 0.001) G_GAN: 3.124 G_L1: 25.084 D_real: 0.027 D_fake: 0.708 \n",
      "(epoch: 76, iters: 350, time: 0.021, data: 0.001) G_GAN: 1.950 G_L1: 27.881 D_real: 0.063 D_fake: 0.268 \n",
      "End of epoch 76 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 77, iters: 100, time: 0.021, data: 0.052) G_GAN: 1.538 G_L1: 28.571 D_real: 0.742 D_fake: 0.521 \n",
      "(epoch: 77, iters: 200, time: 0.078, data: 0.000) G_GAN: 1.943 G_L1: 30.723 D_real: 0.028 D_fake: 0.779 \n",
      "(epoch: 77, iters: 300, time: 0.021, data: 0.001) G_GAN: 2.833 G_L1: 30.517 D_real: 0.089 D_fake: 0.605 \n",
      "End of epoch 77 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 78, iters: 50, time: 0.021, data: 0.000) G_GAN: 1.784 G_L1: 25.030 D_real: 0.341 D_fake: 0.523 \n",
      "(epoch: 78, iters: 150, time: 0.021, data: 0.000) G_GAN: 1.251 G_L1: 29.783 D_real: 0.850 D_fake: 0.147 \n",
      "(epoch: 78, iters: 250, time: 0.079, data: 0.000) G_GAN: 1.950 G_L1: 27.531 D_real: 0.060 D_fake: 0.735 \n",
      "(epoch: 78, iters: 350, time: 0.021, data: 0.001) G_GAN: 2.238 G_L1: 30.460 D_real: 0.200 D_fake: 0.862 \n",
      "End of epoch 78 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 79, iters: 100, time: 0.021, data: 0.056) G_GAN: 1.239 G_L1: 27.617 D_real: 0.812 D_fake: 0.218 \n",
      "(epoch: 79, iters: 200, time: 0.021, data: 0.000) G_GAN: 1.437 G_L1: 25.998 D_real: 0.405 D_fake: 0.453 \n",
      "(epoch: 79, iters: 300, time: 0.079, data: 0.000) G_GAN: 1.303 G_L1: 25.528 D_real: 0.576 D_fake: 0.189 \n",
      "End of epoch 79 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 80, iters: 50, time: 0.021, data: 0.001) G_GAN: 1.421 G_L1: 26.543 D_real: 0.660 D_fake: 0.221 \n",
      "(epoch: 80, iters: 150, time: 0.021, data: 0.001) G_GAN: 1.649 G_L1: 25.521 D_real: 0.234 D_fake: 0.226 \n",
      "(epoch: 80, iters: 250, time: 0.021, data: 0.000) G_GAN: 1.400 G_L1: 27.251 D_real: 0.375 D_fake: 0.350 \n",
      "(epoch: 80, iters: 350, time: 0.081, data: 0.000) G_GAN: 1.481 G_L1: 28.794 D_real: 2.714 D_fake: 0.072 \n",
      "saving the model at the end of epoch 80, iters 28000\n",
      "End of epoch 80 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 81, iters: 100, time: 0.021, data: 0.068) G_GAN: 2.830 G_L1: 28.497 D_real: 0.168 D_fake: 0.105 \n",
      "(epoch: 81, iters: 200, time: 0.020, data: 0.001) G_GAN: 2.522 G_L1: 28.735 D_real: 0.106 D_fake: 0.202 \n",
      "(epoch: 81, iters: 300, time: 0.021, data: 0.000) G_GAN: 0.747 G_L1: 29.117 D_real: 1.375 D_fake: 0.191 \n",
      "End of epoch 81 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 82, iters: 50, time: 0.084, data: 0.000) G_GAN: 0.827 G_L1: 25.942 D_real: 0.734 D_fake: 0.390 \n",
      "(epoch: 82, iters: 150, time: 0.021, data: 0.001) G_GAN: 0.934 G_L1: 24.478 D_real: 0.722 D_fake: 0.229 \n",
      "(epoch: 82, iters: 250, time: 0.021, data: 0.000) G_GAN: 0.822 G_L1: 27.497 D_real: 0.819 D_fake: 0.182 \n",
      "(epoch: 82, iters: 350, time: 0.021, data: 0.000) G_GAN: 2.151 G_L1: 25.294 D_real: 0.051 D_fake: 0.222 \n",
      "End of epoch 82 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 83, iters: 100, time: 0.081, data: 0.054) G_GAN: 1.791 G_L1: 27.446 D_real: 0.217 D_fake: 0.444 \n",
      "(epoch: 83, iters: 200, time: 0.021, data: 0.001) G_GAN: 1.946 G_L1: 28.110 D_real: 0.039 D_fake: 0.832 \n",
      "(epoch: 83, iters: 300, time: 0.021, data: 0.001) G_GAN: 3.176 G_L1: 27.077 D_real: 0.201 D_fake: 0.130 \n",
      "End of epoch 83 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 84, iters: 50, time: 0.021, data: 0.000) G_GAN: 1.983 G_L1: 27.121 D_real: 0.057 D_fake: 0.356 \n",
      "(epoch: 84, iters: 150, time: 0.081, data: 0.000) G_GAN: 2.464 G_L1: 30.567 D_real: 0.037 D_fake: 0.399 \n",
      "(epoch: 84, iters: 250, time: 0.021, data: 0.001) G_GAN: 2.270 G_L1: 31.550 D_real: 0.173 D_fake: 0.156 \n",
      "(epoch: 84, iters: 350, time: 0.020, data: 0.000) G_GAN: 2.227 G_L1: 27.487 D_real: 0.347 D_fake: 0.473 \n",
      "End of epoch 84 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 85, iters: 100, time: 0.020, data: 0.052) G_GAN: 1.992 G_L1: 29.470 D_real: 0.102 D_fake: 0.379 \n",
      "(epoch: 85, iters: 200, time: 0.086, data: 0.000) G_GAN: 1.732 G_L1: 28.085 D_real: 0.252 D_fake: 0.351 \n",
      "(epoch: 85, iters: 300, time: 0.021, data: 0.001) G_GAN: 2.640 G_L1: 26.850 D_real: 0.095 D_fake: 0.501 \n",
      "saving the model at the end of epoch 85, iters 29750\n",
      "End of epoch 85 / 200 \t Time Taken: 5 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 86, iters: 50, time: 0.021, data: 0.000) G_GAN: 2.000 G_L1: 24.970 D_real: 0.232 D_fake: 0.152 \n",
      "(epoch: 86, iters: 150, time: 0.021, data: 0.000) G_GAN: 1.409 G_L1: 29.049 D_real: 0.391 D_fake: 0.286 \n",
      "(epoch: 86, iters: 250, time: 0.088, data: 0.000) G_GAN: 1.690 G_L1: 28.681 D_real: 2.205 D_fake: 0.094 \n",
      "saving the latest model (epoch 86, total_iters 30000)\n",
      "(epoch: 86, iters: 350, time: 0.022, data: 0.001) G_GAN: 1.858 G_L1: 26.357 D_real: 0.228 D_fake: 0.175 \n",
      "End of epoch 86 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 87, iters: 100, time: 0.021, data: 0.035) G_GAN: 1.243 G_L1: 24.651 D_real: 0.219 D_fake: 0.641 \n",
      "(epoch: 87, iters: 200, time: 0.022, data: 0.000) G_GAN: 0.955 G_L1: 29.228 D_real: 0.573 D_fake: 0.254 \n",
      "(epoch: 87, iters: 300, time: 0.082, data: 0.001) G_GAN: 2.623 G_L1: 22.043 D_real: 0.145 D_fake: 0.095 \n",
      "End of epoch 87 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 88, iters: 50, time: 0.021, data: 0.001) G_GAN: 1.719 G_L1: 25.874 D_real: 0.991 D_fake: 0.126 \n",
      "(epoch: 88, iters: 150, time: 0.021, data: 0.000) G_GAN: 1.333 G_L1: 25.037 D_real: 0.353 D_fake: 0.461 \n",
      "(epoch: 88, iters: 250, time: 0.021, data: 0.000) G_GAN: 2.507 G_L1: 29.294 D_real: 0.100 D_fake: 0.171 \n",
      "(epoch: 88, iters: 350, time: 0.082, data: 0.000) G_GAN: 1.080 G_L1: 26.954 D_real: 0.843 D_fake: 0.108 \n",
      "End of epoch 88 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 89, iters: 100, time: 0.021, data: 0.037) G_GAN: 1.564 G_L1: 30.973 D_real: 0.029 D_fake: 0.513 \n",
      "(epoch: 89, iters: 200, time: 0.021, data: 0.000) G_GAN: 2.647 G_L1: 28.381 D_real: 0.015 D_fake: 0.230 \n",
      "(epoch: 89, iters: 300, time: 0.020, data: 0.000) G_GAN: 3.157 G_L1: 20.868 D_real: 0.022 D_fake: 1.235 \n",
      "End of epoch 89 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 90, iters: 50, time: 0.086, data: 0.000) G_GAN: 1.646 G_L1: 26.235 D_real: 0.375 D_fake: 0.447 \n",
      "(epoch: 90, iters: 150, time: 0.020, data: 0.000) G_GAN: 0.715 G_L1: 28.589 D_real: 1.127 D_fake: 0.265 \n",
      "(epoch: 90, iters: 250, time: 0.021, data: 0.000) G_GAN: 2.135 G_L1: 29.570 D_real: 0.135 D_fake: 0.215 \n",
      "(epoch: 90, iters: 350, time: 0.021, data: 0.001) G_GAN: 0.675 G_L1: 25.296 D_real: 1.059 D_fake: 0.264 \n",
      "saving the model at the end of epoch 90, iters 31500\n",
      "End of epoch 90 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 91, iters: 100, time: 0.084, data: 0.061) G_GAN: 0.737 G_L1: 28.378 D_real: 1.114 D_fake: 0.231 \n",
      "(epoch: 91, iters: 200, time: 0.021, data: 0.001) G_GAN: 2.185 G_L1: 29.199 D_real: 0.047 D_fake: 0.355 \n",
      "(epoch: 91, iters: 300, time: 0.021, data: 0.000) G_GAN: 2.474 G_L1: 26.674 D_real: 0.345 D_fake: 0.089 \n",
      "End of epoch 91 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 92, iters: 50, time: 0.021, data: 0.000) G_GAN: 1.001 G_L1: 30.453 D_real: 0.576 D_fake: 0.810 \n",
      "(epoch: 92, iters: 150, time: 0.085, data: 0.000) G_GAN: 2.091 G_L1: 25.627 D_real: 0.187 D_fake: 0.791 \n",
      "(epoch: 92, iters: 250, time: 0.021, data: 0.001) G_GAN: 2.660 G_L1: 28.938 D_real: 0.163 D_fake: 1.085 \n",
      "(epoch: 92, iters: 350, time: 0.021, data: 0.000) G_GAN: 1.817 G_L1: 25.911 D_real: 0.262 D_fake: 0.296 \n",
      "End of epoch 92 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 93, iters: 100, time: 0.020, data: 0.048) G_GAN: 1.844 G_L1: 29.550 D_real: 0.087 D_fake: 1.111 \n",
      "(epoch: 93, iters: 200, time: 0.084, data: 0.001) G_GAN: 1.493 G_L1: 25.660 D_real: 0.307 D_fake: 0.210 \n",
      "(epoch: 93, iters: 300, time: 0.021, data: 0.001) G_GAN: 2.595 G_L1: 26.251 D_real: 0.192 D_fake: 0.168 \n",
      "End of epoch 93 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 94, iters: 50, time: 0.021, data: 0.000) G_GAN: 1.906 G_L1: 29.345 D_real: 0.148 D_fake: 0.381 \n",
      "(epoch: 94, iters: 150, time: 0.021, data: 0.000) G_GAN: 2.274 G_L1: 29.189 D_real: 0.094 D_fake: 0.300 \n",
      "(epoch: 94, iters: 250, time: 0.087, data: 0.000) G_GAN: 1.558 G_L1: 26.621 D_real: 0.865 D_fake: 0.130 \n",
      "(epoch: 94, iters: 350, time: 0.022, data: 0.001) G_GAN: 1.873 G_L1: 26.638 D_real: 1.631 D_fake: 0.049 \n",
      "End of epoch 94 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 95, iters: 100, time: 0.021, data: 0.039) G_GAN: 0.826 G_L1: 25.426 D_real: 1.474 D_fake: 0.081 \n",
      "(epoch: 95, iters: 200, time: 0.021, data: 0.001) G_GAN: 1.052 G_L1: 25.934 D_real: 0.873 D_fake: 0.138 \n",
      "(epoch: 95, iters: 300, time: 0.086, data: 0.000) G_GAN: 1.968 G_L1: 27.582 D_real: 0.084 D_fake: 0.429 \n",
      "saving the model at the end of epoch 95, iters 33250\n",
      "End of epoch 95 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 96, iters: 50, time: 0.021, data: 0.001) G_GAN: 2.289 G_L1: 26.320 D_real: 0.170 D_fake: 0.215 \n",
      "(epoch: 96, iters: 150, time: 0.021, data: 0.000) G_GAN: 2.719 G_L1: 25.793 D_real: 0.072 D_fake: 0.559 \n",
      "(epoch: 96, iters: 250, time: 0.021, data: 0.000) G_GAN: 1.787 G_L1: 24.651 D_real: 0.159 D_fake: 0.311 \n",
      "(epoch: 96, iters: 350, time: 0.087, data: 0.000) G_GAN: 2.512 G_L1: 27.075 D_real: 0.143 D_fake: 0.449 \n",
      "End of epoch 96 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 97, iters: 100, time: 0.021, data: 0.048) G_GAN: 2.492 G_L1: 28.833 D_real: 0.052 D_fake: 0.393 \n",
      "(epoch: 97, iters: 200, time: 0.020, data: 0.000) G_GAN: 2.463 G_L1: 26.186 D_real: 0.088 D_fake: 0.631 \n",
      "(epoch: 97, iters: 300, time: 0.021, data: 0.001) G_GAN: 2.010 G_L1: 27.874 D_real: 0.314 D_fake: 1.161 \n",
      "End of epoch 97 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 98, iters: 50, time: 0.088, data: 0.000) G_GAN: 0.901 G_L1: 30.381 D_real: 0.687 D_fake: 0.367 \n",
      "(epoch: 98, iters: 150, time: 0.022, data: 0.000) G_GAN: 2.095 G_L1: 30.169 D_real: 0.136 D_fake: 0.275 \n",
      "(epoch: 98, iters: 250, time: 0.021, data: 0.000) G_GAN: 1.577 G_L1: 26.535 D_real: 0.509 D_fake: 0.123 \n",
      "(epoch: 98, iters: 350, time: 0.021, data: 0.001) G_GAN: 1.430 G_L1: 25.969 D_real: 0.463 D_fake: 0.449 \n",
      "End of epoch 98 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 99, iters: 100, time: 0.198, data: 0.037) G_GAN: 1.230 G_L1: 27.717 D_real: 1.536 D_fake: 0.123 \n",
      "(epoch: 99, iters: 200, time: 0.021, data: 0.001) G_GAN: 2.320 G_L1: 25.738 D_real: 0.207 D_fake: 0.364 \n",
      "(epoch: 99, iters: 300, time: 0.021, data: 0.000) G_GAN: 2.173 G_L1: 25.108 D_real: 0.187 D_fake: 0.746 \n",
      "End of epoch 99 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0002000 -> 0.0001980\n",
      "(epoch: 100, iters: 50, time: 0.021, data: 0.000) G_GAN: 1.272 G_L1: 22.662 D_real: 0.405 D_fake: 0.064 \n",
      "(epoch: 100, iters: 150, time: 0.089, data: 0.000) G_GAN: 2.495 G_L1: 27.450 D_real: 0.077 D_fake: 0.258 \n",
      "(epoch: 100, iters: 250, time: 0.021, data: 0.000) G_GAN: 1.925 G_L1: 26.613 D_real: 0.316 D_fake: 0.606 \n",
      "(epoch: 100, iters: 350, time: 0.021, data: 0.000) G_GAN: 1.552 G_L1: 28.610 D_real: 0.081 D_fake: 0.728 \n",
      "saving the latest model (epoch 100, total_iters 35000)\n",
      "saving the model at the end of epoch 100, iters 35000\n",
      "End of epoch 100 / 200 \t Time Taken: 5 sec\n",
      "learning rate 0.0001980 -> 0.0001960\n",
      "(epoch: 101, iters: 100, time: 0.021, data: 0.066) G_GAN: 1.356 G_L1: 29.000 D_real: 0.339 D_fake: 0.400 \n",
      "(epoch: 101, iters: 200, time: 0.094, data: 0.000) G_GAN: 1.767 G_L1: 23.740 D_real: 0.441 D_fake: 0.229 \n",
      "(epoch: 101, iters: 300, time: 0.020, data: 0.001) G_GAN: 1.051 G_L1: 30.410 D_real: 0.666 D_fake: 1.012 \n",
      "End of epoch 101 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001960 -> 0.0001941\n",
      "(epoch: 102, iters: 50, time: 0.021, data: 0.000) G_GAN: 1.837 G_L1: 26.811 D_real: 0.050 D_fake: 0.429 \n",
      "(epoch: 102, iters: 150, time: 0.022, data: 0.000) G_GAN: 2.286 G_L1: 27.076 D_real: 0.198 D_fake: 0.381 \n",
      "(epoch: 102, iters: 250, time: 0.089, data: 0.000) G_GAN: 1.327 G_L1: 29.583 D_real: 1.313 D_fake: 0.077 \n",
      "(epoch: 102, iters: 350, time: 0.019, data: 0.001) G_GAN: 2.105 G_L1: 26.147 D_real: 0.735 D_fake: 0.105 \n",
      "End of epoch 102 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001941 -> 0.0001921\n",
      "(epoch: 103, iters: 100, time: 0.021, data: 0.042) G_GAN: 1.042 G_L1: 27.122 D_real: 0.908 D_fake: 0.524 \n",
      "(epoch: 103, iters: 200, time: 0.021, data: 0.000) G_GAN: 2.232 G_L1: 28.225 D_real: 0.264 D_fake: 0.162 \n",
      "(epoch: 103, iters: 300, time: 0.090, data: 0.000) G_GAN: 1.616 G_L1: 28.797 D_real: 0.372 D_fake: 0.416 \n",
      "End of epoch 103 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001921 -> 0.0001901\n",
      "(epoch: 104, iters: 50, time: 0.021, data: 0.001) G_GAN: 1.604 G_L1: 26.822 D_real: 0.167 D_fake: 0.488 \n",
      "(epoch: 104, iters: 150, time: 0.021, data: 0.000) G_GAN: 2.090 G_L1: 23.970 D_real: 0.649 D_fake: 0.156 \n",
      "(epoch: 104, iters: 250, time: 0.021, data: 0.000) G_GAN: 1.831 G_L1: 25.767 D_real: 0.126 D_fake: 0.376 \n",
      "(epoch: 104, iters: 350, time: 0.090, data: 0.001) G_GAN: 1.831 G_L1: 24.393 D_real: 1.107 D_fake: 0.150 \n",
      "End of epoch 104 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001901 -> 0.0001881\n",
      "(epoch: 105, iters: 100, time: 0.021, data: 0.036) G_GAN: 3.604 G_L1: 26.868 D_real: 0.350 D_fake: 0.062 \n",
      "(epoch: 105, iters: 200, time: 0.021, data: 0.001) G_GAN: 2.499 G_L1: 25.391 D_real: 2.406 D_fake: 0.017 \n",
      "(epoch: 105, iters: 300, time: 0.021, data: 0.001) G_GAN: 1.710 G_L1: 25.403 D_real: 0.699 D_fake: 0.164 \n",
      "saving the model at the end of epoch 105, iters 36750\n",
      "End of epoch 105 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001881 -> 0.0001861\n",
      "(epoch: 106, iters: 50, time: 0.090, data: 0.000) G_GAN: 2.105 G_L1: 25.985 D_real: 0.081 D_fake: 0.185 \n",
      "(epoch: 106, iters: 150, time: 0.021, data: 0.000) G_GAN: 2.290 G_L1: 25.554 D_real: 0.147 D_fake: 0.402 \n",
      "(epoch: 106, iters: 250, time: 0.021, data: 0.000) G_GAN: 1.991 G_L1: 30.471 D_real: 0.101 D_fake: 0.500 \n",
      "(epoch: 106, iters: 350, time: 0.021, data: 0.000) G_GAN: 1.771 G_L1: 26.687 D_real: 0.511 D_fake: 0.343 \n",
      "End of epoch 106 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001861 -> 0.0001842\n",
      "(epoch: 107, iters: 100, time: 0.090, data: 0.047) G_GAN: 2.433 G_L1: 30.120 D_real: 0.048 D_fake: 0.881 \n",
      "(epoch: 107, iters: 200, time: 0.021, data: 0.001) G_GAN: 1.162 G_L1: 26.871 D_real: 0.884 D_fake: 0.207 \n",
      "(epoch: 107, iters: 300, time: 0.021, data: 0.001) G_GAN: 1.727 G_L1: 25.778 D_real: 0.094 D_fake: 0.721 \n",
      "End of epoch 107 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001842 -> 0.0001822\n",
      "(epoch: 108, iters: 50, time: 0.021, data: 0.001) G_GAN: 1.336 G_L1: 28.598 D_real: 0.632 D_fake: 0.392 \n",
      "(epoch: 108, iters: 150, time: 0.091, data: 0.000) G_GAN: 1.089 G_L1: 24.028 D_real: 0.826 D_fake: 0.159 \n",
      "(epoch: 108, iters: 250, time: 0.021, data: 0.001) G_GAN: 1.960 G_L1: 27.855 D_real: 0.357 D_fake: 0.348 \n",
      "(epoch: 108, iters: 350, time: 0.020, data: 0.000) G_GAN: 1.064 G_L1: 28.561 D_real: 0.951 D_fake: 0.312 \n",
      "End of epoch 108 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001822 -> 0.0001802\n",
      "(epoch: 109, iters: 100, time: 0.021, data: 0.038) G_GAN: 1.520 G_L1: 28.567 D_real: 0.168 D_fake: 0.784 \n",
      "(epoch: 109, iters: 200, time: 0.091, data: 0.000) G_GAN: 1.990 G_L1: 29.721 D_real: 0.143 D_fake: 0.804 \n",
      "(epoch: 109, iters: 300, time: 0.022, data: 0.001) G_GAN: 2.517 G_L1: 29.591 D_real: 0.067 D_fake: 0.165 \n",
      "End of epoch 109 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001802 -> 0.0001782\n",
      "(epoch: 110, iters: 50, time: 0.021, data: 0.000) G_GAN: 1.930 G_L1: 25.247 D_real: 0.084 D_fake: 0.681 \n",
      "(epoch: 110, iters: 150, time: 0.021, data: 0.000) G_GAN: 1.573 G_L1: 25.861 D_real: 0.643 D_fake: 0.189 \n",
      "(epoch: 110, iters: 250, time: 0.091, data: 0.000) G_GAN: 1.325 G_L1: 26.938 D_real: 0.276 D_fake: 0.357 \n",
      "(epoch: 110, iters: 350, time: 0.020, data: 0.001) G_GAN: 1.953 G_L1: 27.905 D_real: 0.477 D_fake: 0.091 \n",
      "saving the model at the end of epoch 110, iters 38500\n",
      "End of epoch 110 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001782 -> 0.0001762\n",
      "(epoch: 111, iters: 100, time: 0.021, data: 0.061) G_GAN: 1.412 G_L1: 28.180 D_real: 0.591 D_fake: 0.459 \n",
      "(epoch: 111, iters: 200, time: 0.022, data: 0.000) G_GAN: 0.575 G_L1: 23.674 D_real: 1.790 D_fake: 0.252 \n",
      "(epoch: 111, iters: 300, time: 0.210, data: 0.000) G_GAN: 0.666 G_L1: 23.066 D_real: 1.521 D_fake: 0.267 \n",
      "End of epoch 111 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001762 -> 0.0001743\n",
      "(epoch: 112, iters: 50, time: 0.021, data: 0.001) G_GAN: 1.551 G_L1: 26.382 D_real: 0.063 D_fake: 0.888 \n",
      "(epoch: 112, iters: 150, time: 0.021, data: 0.000) G_GAN: 1.210 G_L1: 29.461 D_real: 0.739 D_fake: 0.264 \n",
      "(epoch: 112, iters: 250, time: 0.021, data: 0.000) G_GAN: 1.129 G_L1: 23.243 D_real: 0.579 D_fake: 0.481 \n",
      "(epoch: 112, iters: 350, time: 0.096, data: 0.000) G_GAN: 3.133 G_L1: 28.133 D_real: 0.030 D_fake: 0.949 \n",
      "End of epoch 112 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001743 -> 0.0001723\n",
      "(epoch: 113, iters: 100, time: 0.020, data: 0.039) G_GAN: 1.936 G_L1: 26.411 D_real: 0.023 D_fake: 0.869 \n",
      "(epoch: 113, iters: 200, time: 0.021, data: 0.000) G_GAN: 1.636 G_L1: 29.104 D_real: 0.561 D_fake: 0.213 \n",
      "(epoch: 113, iters: 300, time: 0.021, data: 0.000) G_GAN: 1.303 G_L1: 25.148 D_real: 0.356 D_fake: 0.426 \n",
      "End of epoch 113 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001723 -> 0.0001703\n",
      "(epoch: 114, iters: 50, time: 0.094, data: 0.001) G_GAN: 1.956 G_L1: 30.725 D_real: 0.193 D_fake: 0.392 \n",
      "(epoch: 114, iters: 150, time: 0.021, data: 0.001) G_GAN: 2.058 G_L1: 29.138 D_real: 0.147 D_fake: 0.349 \n",
      "(epoch: 114, iters: 250, time: 0.021, data: 0.000) G_GAN: 2.422 G_L1: 29.956 D_real: 0.019 D_fake: 0.805 \n",
      "(epoch: 114, iters: 350, time: 0.021, data: 0.000) G_GAN: 0.958 G_L1: 26.770 D_real: 1.275 D_fake: 0.336 \n",
      "End of epoch 114 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001703 -> 0.0001683\n",
      "(epoch: 115, iters: 100, time: 0.095, data: 0.038) G_GAN: 2.434 G_L1: 28.514 D_real: 0.075 D_fake: 1.217 \n",
      "saving the latest model (epoch 115, total_iters 40000)\n",
      "(epoch: 115, iters: 200, time: 0.022, data: 0.001) G_GAN: 2.010 G_L1: 27.570 D_real: 0.163 D_fake: 0.897 \n",
      "(epoch: 115, iters: 300, time: 0.020, data: 0.000) G_GAN: 0.706 G_L1: 29.022 D_real: 2.137 D_fake: 0.258 \n",
      "saving the model at the end of epoch 115, iters 40250\n",
      "End of epoch 115 / 200 \t Time Taken: 5 sec\n",
      "learning rate 0.0001683 -> 0.0001663\n",
      "(epoch: 116, iters: 50, time: 0.021, data: 0.000) G_GAN: 1.299 G_L1: 28.656 D_real: 0.466 D_fake: 0.624 \n",
      "(epoch: 116, iters: 150, time: 0.095, data: 0.000) G_GAN: 2.486 G_L1: 24.208 D_real: 0.424 D_fake: 0.092 \n",
      "(epoch: 116, iters: 250, time: 0.021, data: 0.001) G_GAN: 2.745 G_L1: 22.380 D_real: 0.112 D_fake: 0.177 \n",
      "(epoch: 116, iters: 350, time: 0.020, data: 0.000) G_GAN: 2.340 G_L1: 25.927 D_real: 0.090 D_fake: 0.296 \n",
      "End of epoch 116 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001663 -> 0.0001644\n",
      "(epoch: 117, iters: 100, time: 0.021, data: 0.048) G_GAN: 1.695 G_L1: 28.054 D_real: 0.350 D_fake: 0.378 \n",
      "(epoch: 117, iters: 200, time: 0.096, data: 0.000) G_GAN: 2.315 G_L1: 30.276 D_real: 0.119 D_fake: 0.233 \n",
      "(epoch: 117, iters: 300, time: 0.021, data: 0.001) G_GAN: 1.956 G_L1: 29.395 D_real: 0.123 D_fake: 0.403 \n",
      "End of epoch 117 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001644 -> 0.0001624\n",
      "(epoch: 118, iters: 50, time: 0.021, data: 0.000) G_GAN: 2.344 G_L1: 30.717 D_real: 0.012 D_fake: 0.742 \n",
      "(epoch: 118, iters: 150, time: 0.022, data: 0.000) G_GAN: 2.432 G_L1: 29.596 D_real: 0.130 D_fake: 0.403 \n",
      "(epoch: 118, iters: 250, time: 0.096, data: 0.001) G_GAN: 2.428 G_L1: 30.156 D_real: 0.213 D_fake: 0.246 \n",
      "(epoch: 118, iters: 350, time: 0.022, data: 0.001) G_GAN: 2.565 G_L1: 25.889 D_real: 0.035 D_fake: 1.307 \n",
      "End of epoch 118 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001624 -> 0.0001604\n",
      "(epoch: 119, iters: 100, time: 0.022, data: 0.044) G_GAN: 1.510 G_L1: 24.101 D_real: 0.448 D_fake: 0.234 \n",
      "(epoch: 119, iters: 200, time: 0.022, data: 0.001) G_GAN: 1.628 G_L1: 20.706 D_real: 0.429 D_fake: 0.145 \n",
      "(epoch: 119, iters: 300, time: 0.097, data: 0.001) G_GAN: 2.326 G_L1: 21.819 D_real: 0.016 D_fake: 0.298 \n",
      "End of epoch 119 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001604 -> 0.0001584\n",
      "(epoch: 120, iters: 50, time: 0.021, data: 0.001) G_GAN: 1.290 G_L1: 28.266 D_real: 0.281 D_fake: 0.887 \n",
      "(epoch: 120, iters: 150, time: 0.022, data: 0.000) G_GAN: 2.446 G_L1: 26.694 D_real: 0.037 D_fake: 0.436 \n",
      "(epoch: 120, iters: 250, time: 0.022, data: 0.001) G_GAN: 1.630 G_L1: 24.875 D_real: 0.289 D_fake: 0.435 \n",
      "(epoch: 120, iters: 350, time: 0.098, data: 0.000) G_GAN: 1.987 G_L1: 26.446 D_real: 0.110 D_fake: 0.992 \n",
      "saving the model at the end of epoch 120, iters 42000\n",
      "End of epoch 120 / 200 \t Time Taken: 5 sec\n",
      "learning rate 0.0001584 -> 0.0001564\n",
      "(epoch: 121, iters: 100, time: 0.022, data: 0.059) G_GAN: 1.835 G_L1: 30.234 D_real: 0.083 D_fake: 0.836 \n",
      "(epoch: 121, iters: 200, time: 0.022, data: 0.000) G_GAN: 2.114 G_L1: 29.032 D_real: 0.019 D_fake: 0.472 \n",
      "(epoch: 121, iters: 300, time: 0.022, data: 0.001) G_GAN: 1.844 G_L1: 29.704 D_real: 0.333 D_fake: 0.601 \n",
      "End of epoch 121 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001564 -> 0.0001545\n",
      "(epoch: 122, iters: 50, time: 0.216, data: 0.000) G_GAN: 2.083 G_L1: 28.677 D_real: 0.253 D_fake: 0.264 \n",
      "(epoch: 122, iters: 150, time: 0.023, data: 0.001) G_GAN: 1.779 G_L1: 27.317 D_real: 0.675 D_fake: 0.131 \n",
      "(epoch: 122, iters: 250, time: 0.022, data: 0.001) G_GAN: 1.229 G_L1: 24.780 D_real: 0.502 D_fake: 0.493 \n",
      "(epoch: 122, iters: 350, time: 0.022, data: 0.000) G_GAN: 2.238 G_L1: 30.597 D_real: 0.088 D_fake: 0.489 \n",
      "End of epoch 122 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001545 -> 0.0001525\n",
      "(epoch: 123, iters: 100, time: 0.100, data: 0.042) G_GAN: 2.668 G_L1: 23.310 D_real: 0.012 D_fake: 1.239 \n",
      "(epoch: 123, iters: 200, time: 0.021, data: 0.001) G_GAN: 1.609 G_L1: 25.341 D_real: 0.115 D_fake: 0.655 \n",
      "(epoch: 123, iters: 300, time: 0.021, data: 0.001) G_GAN: 2.148 G_L1: 28.675 D_real: 0.033 D_fake: 0.451 \n",
      "End of epoch 123 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001525 -> 0.0001505\n",
      "(epoch: 124, iters: 50, time: 0.022, data: 0.000) G_GAN: 1.772 G_L1: 28.572 D_real: 0.190 D_fake: 0.800 \n",
      "(epoch: 124, iters: 150, time: 0.101, data: 0.000) G_GAN: 1.214 G_L1: 25.315 D_real: 0.592 D_fake: 0.387 \n",
      "(epoch: 124, iters: 250, time: 0.023, data: 0.001) G_GAN: 1.811 G_L1: 27.774 D_real: 0.395 D_fake: 0.176 \n",
      "(epoch: 124, iters: 350, time: 0.023, data: 0.000) G_GAN: 1.793 G_L1: 27.716 D_real: 0.285 D_fake: 0.377 \n",
      "End of epoch 124 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001505 -> 0.0001485\n",
      "(epoch: 125, iters: 100, time: 0.021, data: 0.041) G_GAN: 1.583 G_L1: 23.385 D_real: 0.534 D_fake: 0.117 \n",
      "(epoch: 125, iters: 200, time: 0.100, data: 0.000) G_GAN: 1.409 G_L1: 29.883 D_real: 0.196 D_fake: 0.539 \n",
      "(epoch: 125, iters: 300, time: 0.021, data: 0.001) G_GAN: 1.552 G_L1: 25.431 D_real: 1.257 D_fake: 0.174 \n",
      "saving the model at the end of epoch 125, iters 43750\n",
      "End of epoch 125 / 200 \t Time Taken: 5 sec\n",
      "learning rate 0.0001485 -> 0.0001465\n",
      "(epoch: 126, iters: 50, time: 0.022, data: 0.000) G_GAN: 2.017 G_L1: 24.316 D_real: 0.442 D_fake: 0.130 \n",
      "(epoch: 126, iters: 150, time: 0.021, data: 0.001) G_GAN: 1.831 G_L1: 29.039 D_real: 0.087 D_fake: 0.888 \n",
      "(epoch: 126, iters: 250, time: 0.099, data: 0.000) G_GAN: 1.741 G_L1: 24.764 D_real: 0.822 D_fake: 0.161 \n",
      "(epoch: 126, iters: 350, time: 0.021, data: 0.001) G_GAN: 1.074 G_L1: 25.910 D_real: 1.052 D_fake: 0.206 \n",
      "End of epoch 126 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001465 -> 0.0001446\n",
      "(epoch: 127, iters: 100, time: 0.021, data: 0.055) G_GAN: 1.467 G_L1: 26.643 D_real: 0.251 D_fake: 1.016 \n",
      "(epoch: 127, iters: 200, time: 0.021, data: 0.000) G_GAN: 2.048 G_L1: 27.780 D_real: 0.223 D_fake: 0.179 \n",
      "(epoch: 127, iters: 300, time: 0.100, data: 0.001) G_GAN: 1.223 G_L1: 26.113 D_real: 0.446 D_fake: 0.525 \n",
      "End of epoch 127 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001446 -> 0.0001426\n",
      "(epoch: 128, iters: 50, time: 0.022, data: 0.001) G_GAN: 1.987 G_L1: 26.869 D_real: 0.057 D_fake: 0.399 \n",
      "(epoch: 128, iters: 150, time: 0.022, data: 0.001) G_GAN: 1.523 G_L1: 25.828 D_real: 0.488 D_fake: 0.196 \n",
      "(epoch: 128, iters: 250, time: 0.021, data: 0.000) G_GAN: 2.668 G_L1: 27.737 D_real: 0.152 D_fake: 0.193 \n",
      "(epoch: 128, iters: 350, time: 0.102, data: 0.000) G_GAN: 2.005 G_L1: 26.769 D_real: 0.135 D_fake: 0.374 \n",
      "End of epoch 128 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001426 -> 0.0001406\n",
      "(epoch: 129, iters: 100, time: 0.022, data: 0.056) G_GAN: 1.474 G_L1: 25.683 D_real: 0.281 D_fake: 0.828 \n",
      "(epoch: 129, iters: 200, time: 0.021, data: 0.001) G_GAN: 1.952 G_L1: 26.485 D_real: 0.036 D_fake: 0.303 \n",
      "saving the latest model (epoch 129, total_iters 45000)\n",
      "(epoch: 129, iters: 300, time: 0.022, data: 0.001) G_GAN: 0.846 G_L1: 22.973 D_real: 0.560 D_fake: 0.629 \n",
      "End of epoch 129 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001406 -> 0.0001386\n",
      "(epoch: 130, iters: 50, time: 0.103, data: 0.000) G_GAN: 2.010 G_L1: 30.661 D_real: 0.069 D_fake: 0.968 \n",
      "(epoch: 130, iters: 150, time: 0.022, data: 0.001) G_GAN: 1.846 G_L1: 23.029 D_real: 0.082 D_fake: 0.386 \n",
      "(epoch: 130, iters: 250, time: 0.020, data: 0.000) G_GAN: 2.063 G_L1: 28.376 D_real: 0.134 D_fake: 0.690 \n",
      "(epoch: 130, iters: 350, time: 0.023, data: 0.000) G_GAN: 0.793 G_L1: 23.639 D_real: 1.724 D_fake: 0.437 \n",
      "saving the model at the end of epoch 130, iters 45500\n",
      "End of epoch 130 / 200 \t Time Taken: 5 sec\n",
      "learning rate 0.0001386 -> 0.0001366\n",
      "(epoch: 131, iters: 100, time: 0.102, data: 0.069) G_GAN: 0.977 G_L1: 24.856 D_real: 0.835 D_fake: 0.291 \n",
      "(epoch: 131, iters: 200, time: 0.022, data: 0.001) G_GAN: 1.178 G_L1: 25.910 D_real: 0.609 D_fake: 0.262 \n",
      "(epoch: 131, iters: 300, time: 0.021, data: 0.000) G_GAN: 0.783 G_L1: 27.899 D_real: 1.101 D_fake: 0.258 \n",
      "End of epoch 131 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001366 -> 0.0001347\n",
      "(epoch: 132, iters: 50, time: 0.021, data: 0.000) G_GAN: 0.680 G_L1: 23.750 D_real: 0.826 D_fake: 0.354 \n",
      "(epoch: 132, iters: 150, time: 0.221, data: 0.000) G_GAN: 1.632 G_L1: 26.751 D_real: 0.178 D_fake: 0.629 \n",
      "(epoch: 132, iters: 250, time: 0.021, data: 0.001) G_GAN: 1.482 G_L1: 24.107 D_real: 0.199 D_fake: 0.551 \n",
      "(epoch: 132, iters: 350, time: 0.021, data: 0.000) G_GAN: 2.338 G_L1: 30.565 D_real: 0.016 D_fake: 0.500 \n",
      "End of epoch 132 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001347 -> 0.0001327\n",
      "(epoch: 133, iters: 100, time: 0.022, data: 0.046) G_GAN: 1.516 G_L1: 25.965 D_real: 0.494 D_fake: 0.264 \n",
      "(epoch: 133, iters: 200, time: 0.102, data: 0.001) G_GAN: 2.141 G_L1: 28.132 D_real: 0.202 D_fake: 0.205 \n",
      "(epoch: 133, iters: 300, time: 0.023, data: 0.001) G_GAN: 2.520 G_L1: 28.143 D_real: 0.123 D_fake: 0.538 \n",
      "End of epoch 133 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001327 -> 0.0001307\n",
      "(epoch: 134, iters: 50, time: 0.022, data: 0.000) G_GAN: 1.984 G_L1: 29.128 D_real: 0.438 D_fake: 0.097 \n",
      "(epoch: 134, iters: 150, time: 0.022, data: 0.001) G_GAN: 1.819 G_L1: 27.039 D_real: 0.369 D_fake: 0.409 \n",
      "(epoch: 134, iters: 250, time: 0.104, data: 0.001) G_GAN: 1.663 G_L1: 24.031 D_real: 0.449 D_fake: 0.173 \n",
      "(epoch: 134, iters: 350, time: 0.021, data: 0.001) G_GAN: 2.448 G_L1: 27.332 D_real: 0.420 D_fake: 0.080 \n",
      "End of epoch 134 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001307 -> 0.0001287\n",
      "(epoch: 135, iters: 100, time: 0.022, data: 0.045) G_GAN: 1.439 G_L1: 26.695 D_real: 0.105 D_fake: 0.427 \n",
      "(epoch: 135, iters: 200, time: 0.022, data: 0.000) G_GAN: 0.787 G_L1: 25.733 D_real: 0.723 D_fake: 0.350 \n",
      "(epoch: 135, iters: 300, time: 0.103, data: 0.000) G_GAN: 2.040 G_L1: 27.235 D_real: 0.081 D_fake: 0.586 \n",
      "saving the model at the end of epoch 135, iters 47250\n",
      "End of epoch 135 / 200 \t Time Taken: 5 sec\n",
      "learning rate 0.0001287 -> 0.0001267\n",
      "(epoch: 136, iters: 50, time: 0.021, data: 0.001) G_GAN: 2.095 G_L1: 26.657 D_real: 0.020 D_fake: 0.190 \n",
      "(epoch: 136, iters: 150, time: 0.023, data: 0.000) G_GAN: 1.830 G_L1: 24.384 D_real: 0.644 D_fake: 0.172 \n",
      "(epoch: 136, iters: 250, time: 0.021, data: 0.000) G_GAN: 2.170 G_L1: 30.671 D_real: 0.070 D_fake: 0.523 \n",
      "(epoch: 136, iters: 350, time: 0.105, data: 0.001) G_GAN: 1.057 G_L1: 27.105 D_real: 1.318 D_fake: 0.292 \n",
      "End of epoch 136 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001267 -> 0.0001248\n",
      "(epoch: 137, iters: 100, time: 0.022, data: 0.043) G_GAN: 1.361 G_L1: 29.394 D_real: 0.513 D_fake: 0.323 \n",
      "(epoch: 137, iters: 200, time: 0.021, data: 0.000) G_GAN: 1.815 G_L1: 26.137 D_real: 0.405 D_fake: 0.286 \n",
      "(epoch: 137, iters: 300, time: 0.022, data: 0.000) G_GAN: 1.844 G_L1: 25.564 D_real: 0.139 D_fake: 0.429 \n",
      "End of epoch 137 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001248 -> 0.0001228\n",
      "(epoch: 138, iters: 50, time: 0.103, data: 0.000) G_GAN: 2.038 G_L1: 26.152 D_real: 0.189 D_fake: 0.245 \n",
      "(epoch: 138, iters: 150, time: 0.023, data: 0.001) G_GAN: 1.424 G_L1: 24.467 D_real: 0.489 D_fake: 0.321 \n",
      "(epoch: 138, iters: 250, time: 0.022, data: 0.001) G_GAN: 2.056 G_L1: 28.423 D_real: 0.590 D_fake: 0.132 \n",
      "(epoch: 138, iters: 350, time: 0.022, data: 0.001) G_GAN: 2.929 G_L1: 28.881 D_real: 0.202 D_fake: 0.127 \n",
      "End of epoch 138 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001228 -> 0.0001208\n",
      "(epoch: 139, iters: 100, time: 0.110, data: 0.054) G_GAN: 1.452 G_L1: 25.443 D_real: 0.705 D_fake: 0.143 \n",
      "(epoch: 139, iters: 200, time: 0.021, data: 0.001) G_GAN: 2.905 G_L1: 26.441 D_real: 0.748 D_fake: 0.040 \n",
      "(epoch: 139, iters: 300, time: 0.022, data: 0.000) G_GAN: 1.825 G_L1: 30.493 D_real: 0.355 D_fake: 0.241 \n",
      "End of epoch 139 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001208 -> 0.0001188\n",
      "(epoch: 140, iters: 50, time: 0.022, data: 0.001) G_GAN: 1.221 G_L1: 27.392 D_real: 1.503 D_fake: 0.176 \n",
      "(epoch: 140, iters: 150, time: 0.106, data: 0.000) G_GAN: 1.541 G_L1: 25.719 D_real: 0.112 D_fake: 0.607 \n",
      "(epoch: 140, iters: 250, time: 0.022, data: 0.001) G_GAN: 1.416 G_L1: 31.348 D_real: 0.508 D_fake: 0.172 \n",
      "(epoch: 140, iters: 350, time: 0.022, data: 0.001) G_GAN: 1.322 G_L1: 23.452 D_real: 0.098 D_fake: 0.694 \n",
      "saving the model at the end of epoch 140, iters 49000\n",
      "End of epoch 140 / 200 \t Time Taken: 5 sec\n",
      "learning rate 0.0001188 -> 0.0001168\n",
      "(epoch: 141, iters: 100, time: 0.023, data: 0.060) G_GAN: 1.804 G_L1: 24.826 D_real: 0.247 D_fake: 0.258 \n",
      "(epoch: 141, iters: 200, time: 0.223, data: 0.000) G_GAN: 1.718 G_L1: 28.511 D_real: 0.163 D_fake: 0.329 \n",
      "(epoch: 141, iters: 300, time: 0.021, data: 0.001) G_GAN: 2.608 G_L1: 27.518 D_real: 0.077 D_fake: 0.134 \n",
      "End of epoch 141 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001168 -> 0.0001149\n",
      "(epoch: 142, iters: 50, time: 0.022, data: 0.000) G_GAN: 1.533 G_L1: 27.387 D_real: 0.267 D_fake: 0.603 \n",
      "(epoch: 142, iters: 150, time: 0.021, data: 0.000) G_GAN: 2.272 G_L1: 24.202 D_real: 0.469 D_fake: 0.111 \n",
      "(epoch: 142, iters: 250, time: 0.106, data: 0.000) G_GAN: 1.923 G_L1: 28.732 D_real: 0.083 D_fake: 0.634 \n",
      "(epoch: 142, iters: 350, time: 0.023, data: 0.001) G_GAN: 1.801 G_L1: 19.982 D_real: 0.634 D_fake: 0.404 \n",
      "End of epoch 142 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001149 -> 0.0001129\n",
      "(epoch: 143, iters: 100, time: 0.021, data: 0.049) G_GAN: 1.976 G_L1: 27.053 D_real: 0.275 D_fake: 0.356 \n",
      "(epoch: 143, iters: 200, time: 0.021, data: 0.001) G_GAN: 1.577 G_L1: 26.443 D_real: 0.627 D_fake: 0.115 \n",
      "(epoch: 143, iters: 300, time: 0.106, data: 0.000) G_GAN: 1.964 G_L1: 30.818 D_real: 0.065 D_fake: 1.454 \n",
      "saving the latest model (epoch 143, total_iters 50000)\n",
      "End of epoch 143 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001129 -> 0.0001109\n",
      "(epoch: 144, iters: 50, time: 0.021, data: 0.001) G_GAN: 1.529 G_L1: 29.561 D_real: 0.022 D_fake: 1.868 \n",
      "(epoch: 144, iters: 150, time: 0.021, data: 0.001) G_GAN: 2.691 G_L1: 26.027 D_real: 0.235 D_fake: 0.135 \n",
      "(epoch: 144, iters: 250, time: 0.021, data: 0.001) G_GAN: 1.984 G_L1: 24.085 D_real: 1.598 D_fake: 0.042 \n",
      "(epoch: 144, iters: 350, time: 0.106, data: 0.000) G_GAN: 2.425 G_L1: 29.099 D_real: 0.071 D_fake: 1.336 \n",
      "End of epoch 144 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001109 -> 0.0001089\n",
      "(epoch: 145, iters: 100, time: 0.022, data: 0.050) G_GAN: 1.645 G_L1: 27.209 D_real: 0.356 D_fake: 0.535 \n",
      "(epoch: 145, iters: 200, time: 0.023, data: 0.000) G_GAN: 0.739 G_L1: 25.497 D_real: 0.746 D_fake: 0.518 \n",
      "(epoch: 145, iters: 300, time: 0.022, data: 0.001) G_GAN: 1.231 G_L1: 28.643 D_real: 0.550 D_fake: 0.522 \n",
      "saving the model at the end of epoch 145, iters 50750\n",
      "End of epoch 145 / 200 \t Time Taken: 5 sec\n",
      "learning rate 0.0001089 -> 0.0001069\n",
      "(epoch: 146, iters: 50, time: 0.106, data: 0.001) G_GAN: 2.497 G_L1: 29.159 D_real: 0.106 D_fake: 0.139 \n",
      "(epoch: 146, iters: 150, time: 0.022, data: 0.001) G_GAN: 1.577 G_L1: 21.834 D_real: 0.686 D_fake: 0.121 \n",
      "(epoch: 146, iters: 250, time: 0.022, data: 0.000) G_GAN: 0.966 G_L1: 24.865 D_real: 1.217 D_fake: 0.373 \n",
      "(epoch: 146, iters: 350, time: 0.022, data: 0.000) G_GAN: 1.862 G_L1: 27.557 D_real: 0.930 D_fake: 0.116 \n",
      "End of epoch 146 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001069 -> 0.0001050\n",
      "(epoch: 147, iters: 100, time: 0.108, data: 0.046) G_GAN: 1.244 G_L1: 24.889 D_real: 0.463 D_fake: 0.517 \n",
      "(epoch: 147, iters: 200, time: 0.021, data: 0.001) G_GAN: 1.272 G_L1: 26.702 D_real: 0.368 D_fake: 0.537 \n",
      "(epoch: 147, iters: 300, time: 0.022, data: 0.000) G_GAN: 2.495 G_L1: 29.477 D_real: 0.035 D_fake: 0.224 \n",
      "End of epoch 147 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001050 -> 0.0001030\n",
      "(epoch: 148, iters: 50, time: 0.021, data: 0.001) G_GAN: 1.587 G_L1: 29.016 D_real: 0.145 D_fake: 0.832 \n",
      "(epoch: 148, iters: 150, time: 0.108, data: 0.000) G_GAN: 1.610 G_L1: 30.430 D_real: 0.115 D_fake: 0.755 \n",
      "(epoch: 148, iters: 250, time: 0.022, data: 0.001) G_GAN: 1.747 G_L1: 26.744 D_real: 0.326 D_fake: 0.225 \n",
      "(epoch: 148, iters: 350, time: 0.021, data: 0.000) G_GAN: 2.548 G_L1: 24.779 D_real: 0.271 D_fake: 0.099 \n",
      "End of epoch 148 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001030 -> 0.0001010\n",
      "(epoch: 149, iters: 100, time: 0.021, data: 0.048) G_GAN: 1.155 G_L1: 27.415 D_real: 1.190 D_fake: 0.217 \n",
      "(epoch: 149, iters: 200, time: 0.109, data: 0.000) G_GAN: 2.178 G_L1: 26.800 D_real: 0.586 D_fake: 0.106 \n",
      "(epoch: 149, iters: 300, time: 0.021, data: 0.001) G_GAN: 1.345 G_L1: 27.843 D_real: 0.054 D_fake: 0.960 \n",
      "End of epoch 149 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0001010 -> 0.0000990\n",
      "(epoch: 150, iters: 50, time: 0.021, data: 0.000) G_GAN: 1.911 G_L1: 26.713 D_real: 0.221 D_fake: 0.297 \n",
      "(epoch: 150, iters: 150, time: 0.021, data: 0.000) G_GAN: 1.935 G_L1: 28.928 D_real: 0.245 D_fake: 0.226 \n",
      "(epoch: 150, iters: 250, time: 0.224, data: 0.001) G_GAN: 2.399 G_L1: 25.904 D_real: 0.494 D_fake: 0.127 \n",
      "(epoch: 150, iters: 350, time: 0.022, data: 0.001) G_GAN: 1.820 G_L1: 27.715 D_real: 0.159 D_fake: 0.293 \n",
      "saving the model at the end of epoch 150, iters 52500\n",
      "End of epoch 150 / 200 \t Time Taken: 5 sec\n",
      "learning rate 0.0000990 -> 0.0000970\n",
      "(epoch: 151, iters: 100, time: 0.021, data: 0.066) G_GAN: 2.838 G_L1: 26.538 D_real: 0.744 D_fake: 0.059 \n",
      "(epoch: 151, iters: 200, time: 0.021, data: 0.001) G_GAN: 1.735 G_L1: 29.481 D_real: 0.272 D_fake: 0.745 \n",
      "(epoch: 151, iters: 300, time: 0.112, data: 0.000) G_GAN: 1.873 G_L1: 25.883 D_real: 0.240 D_fake: 0.433 \n",
      "End of epoch 151 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000970 -> 0.0000950\n",
      "(epoch: 152, iters: 50, time: 0.022, data: 0.001) G_GAN: 1.121 G_L1: 25.871 D_real: 0.816 D_fake: 0.534 \n",
      "(epoch: 152, iters: 150, time: 0.021, data: 0.000) G_GAN: 1.115 G_L1: 28.902 D_real: 0.451 D_fake: 0.688 \n",
      "(epoch: 152, iters: 250, time: 0.021, data: 0.000) G_GAN: 1.326 G_L1: 28.516 D_real: 0.225 D_fake: 0.734 \n",
      "(epoch: 152, iters: 350, time: 0.109, data: 0.000) G_GAN: 1.648 G_L1: 30.970 D_real: 0.035 D_fake: 0.889 \n",
      "End of epoch 152 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000950 -> 0.0000931\n",
      "(epoch: 153, iters: 100, time: 0.022, data: 0.047) G_GAN: 1.726 G_L1: 26.448 D_real: 0.172 D_fake: 0.525 \n",
      "(epoch: 153, iters: 200, time: 0.023, data: 0.001) G_GAN: 1.600 G_L1: 25.373 D_real: 0.212 D_fake: 0.271 \n",
      "(epoch: 153, iters: 300, time: 0.021, data: 0.001) G_GAN: 1.478 G_L1: 25.516 D_real: 0.343 D_fake: 0.625 \n",
      "End of epoch 153 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000931 -> 0.0000911\n",
      "(epoch: 154, iters: 50, time: 0.111, data: 0.000) G_GAN: 1.312 G_L1: 24.689 D_real: 0.484 D_fake: 0.259 \n",
      "(epoch: 154, iters: 150, time: 0.020, data: 0.001) G_GAN: 1.777 G_L1: 23.337 D_real: 0.584 D_fake: 0.179 \n",
      "(epoch: 154, iters: 250, time: 0.022, data: 0.001) G_GAN: 2.838 G_L1: 26.573 D_real: 0.393 D_fake: 0.056 \n",
      "(epoch: 154, iters: 350, time: 0.021, data: 0.000) G_GAN: 1.494 G_L1: 24.793 D_real: 0.165 D_fake: 0.830 \n",
      "End of epoch 154 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000911 -> 0.0000891\n",
      "(epoch: 155, iters: 100, time: 0.110, data: 0.047) G_GAN: 1.998 G_L1: 28.796 D_real: 0.424 D_fake: 0.233 \n",
      "(epoch: 155, iters: 200, time: 0.021, data: 0.001) G_GAN: 1.766 G_L1: 25.341 D_real: 0.317 D_fake: 0.326 \n",
      "(epoch: 155, iters: 300, time: 0.022, data: 0.001) G_GAN: 1.491 G_L1: 28.573 D_real: 0.243 D_fake: 0.543 \n",
      "saving the model at the end of epoch 155, iters 54250\n",
      "End of epoch 155 / 200 \t Time Taken: 5 sec\n",
      "learning rate 0.0000891 -> 0.0000871\n",
      "(epoch: 156, iters: 50, time: 0.021, data: 0.000) G_GAN: 1.365 G_L1: 29.343 D_real: 0.796 D_fake: 0.317 \n",
      "(epoch: 156, iters: 150, time: 0.111, data: 0.000) G_GAN: 1.865 G_L1: 28.477 D_real: 0.183 D_fake: 0.374 \n",
      "(epoch: 156, iters: 250, time: 0.021, data: 0.001) G_GAN: 2.243 G_L1: 26.335 D_real: 0.650 D_fake: 0.120 \n",
      "(epoch: 156, iters: 350, time: 0.021, data: 0.001) G_GAN: 1.550 G_L1: 25.380 D_real: 0.047 D_fake: 1.604 \n",
      "End of epoch 156 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000871 -> 0.0000851\n",
      "(epoch: 157, iters: 100, time: 0.021, data: 0.047) G_GAN: 2.252 G_L1: 26.401 D_real: 0.259 D_fake: 0.180 \n",
      "(epoch: 157, iters: 200, time: 0.112, data: 0.001) G_GAN: 2.193 G_L1: 25.450 D_real: 0.069 D_fake: 0.346 \n",
      "(epoch: 157, iters: 300, time: 0.021, data: 0.001) G_GAN: 2.777 G_L1: 23.391 D_real: 0.105 D_fake: 0.334 \n",
      "End of epoch 157 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000851 -> 0.0000832\n",
      "(epoch: 158, iters: 50, time: 0.021, data: 0.000) G_GAN: 1.480 G_L1: 31.443 D_real: 0.358 D_fake: 0.425 \n",
      "saving the latest model (epoch 158, total_iters 55000)\n",
      "(epoch: 158, iters: 150, time: 0.022, data: 0.001) G_GAN: 1.481 G_L1: 25.505 D_real: 0.989 D_fake: 0.175 \n",
      "(epoch: 158, iters: 250, time: 0.232, data: 0.000) G_GAN: 1.312 G_L1: 24.849 D_real: 0.643 D_fake: 0.218 \n",
      "(epoch: 158, iters: 350, time: 0.023, data: 0.001) G_GAN: 1.132 G_L1: 28.097 D_real: 0.311 D_fake: 1.098 \n",
      "End of epoch 158 / 200 \t Time Taken: 5 sec\n",
      "learning rate 0.0000832 -> 0.0000812\n",
      "(epoch: 159, iters: 100, time: 0.022, data: 0.050) G_GAN: 1.209 G_L1: 27.124 D_real: 0.300 D_fake: 0.476 \n",
      "(epoch: 159, iters: 200, time: 0.021, data: 0.001) G_GAN: 2.204 G_L1: 25.937 D_real: 0.154 D_fake: 0.196 \n",
      "(epoch: 159, iters: 300, time: 0.119, data: 0.000) G_GAN: 1.606 G_L1: 27.782 D_real: 0.274 D_fake: 0.422 \n",
      "End of epoch 159 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000812 -> 0.0000792\n",
      "(epoch: 160, iters: 50, time: 0.021, data: 0.001) G_GAN: 2.054 G_L1: 28.687 D_real: 0.158 D_fake: 0.178 \n",
      "(epoch: 160, iters: 150, time: 0.021, data: 0.000) G_GAN: 2.795 G_L1: 28.267 D_real: 0.331 D_fake: 0.105 \n",
      "(epoch: 160, iters: 250, time: 0.022, data: 0.000) G_GAN: 1.669 G_L1: 27.950 D_real: 0.121 D_fake: 0.673 \n",
      "(epoch: 160, iters: 350, time: 0.113, data: 0.000) G_GAN: 1.090 G_L1: 22.537 D_real: 1.228 D_fake: 0.275 \n",
      "saving the model at the end of epoch 160, iters 56000\n",
      "End of epoch 160 / 200 \t Time Taken: 5 sec\n",
      "learning rate 0.0000792 -> 0.0000772\n",
      "(epoch: 161, iters: 100, time: 0.021, data: 0.065) G_GAN: 1.361 G_L1: 25.286 D_real: 0.216 D_fake: 0.906 \n",
      "(epoch: 161, iters: 200, time: 0.021, data: 0.001) G_GAN: 1.761 G_L1: 28.430 D_real: 0.568 D_fake: 0.181 \n",
      "(epoch: 161, iters: 300, time: 0.022, data: 0.000) G_GAN: 1.658 G_L1: 28.009 D_real: 0.107 D_fake: 0.349 \n",
      "End of epoch 161 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000772 -> 0.0000752\n",
      "(epoch: 162, iters: 50, time: 0.115, data: 0.000) G_GAN: 1.480 G_L1: 24.660 D_real: 0.275 D_fake: 0.421 \n",
      "(epoch: 162, iters: 150, time: 0.020, data: 0.001) G_GAN: 1.369 G_L1: 25.977 D_real: 1.715 D_fake: 0.124 \n",
      "(epoch: 162, iters: 250, time: 0.022, data: 0.001) G_GAN: 2.641 G_L1: 24.364 D_real: 0.240 D_fake: 0.124 \n",
      "(epoch: 162, iters: 350, time: 0.021, data: 0.001) G_GAN: 1.900 G_L1: 28.168 D_real: 0.673 D_fake: 0.230 \n",
      "End of epoch 162 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000752 -> 0.0000733\n",
      "(epoch: 163, iters: 100, time: 0.115, data: 0.051) G_GAN: 1.203 G_L1: 30.584 D_real: 0.104 D_fake: 0.965 \n",
      "(epoch: 163, iters: 200, time: 0.021, data: 0.001) G_GAN: 1.834 G_L1: 29.699 D_real: 0.280 D_fake: 0.502 \n",
      "(epoch: 163, iters: 300, time: 0.020, data: 0.001) G_GAN: 1.298 G_L1: 26.211 D_real: 0.229 D_fake: 0.751 \n",
      "End of epoch 163 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000733 -> 0.0000713\n",
      "(epoch: 164, iters: 50, time: 0.020, data: 0.001) G_GAN: 1.978 G_L1: 26.042 D_real: 0.651 D_fake: 0.126 \n",
      "(epoch: 164, iters: 150, time: 0.118, data: 0.001) G_GAN: 1.998 G_L1: 25.544 D_real: 0.531 D_fake: 0.088 \n",
      "(epoch: 164, iters: 250, time: 0.021, data: 0.001) G_GAN: 2.781 G_L1: 29.132 D_real: 0.209 D_fake: 0.100 \n",
      "(epoch: 164, iters: 350, time: 0.022, data: 0.001) G_GAN: 2.604 G_L1: 26.187 D_real: 0.422 D_fake: 0.094 \n",
      "End of epoch 164 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000713 -> 0.0000693\n",
      "(epoch: 165, iters: 100, time: 0.021, data: 0.048) G_GAN: 1.696 G_L1: 28.112 D_real: 0.404 D_fake: 0.315 \n",
      "(epoch: 165, iters: 200, time: 0.116, data: 0.000) G_GAN: 2.208 G_L1: 29.017 D_real: 0.742 D_fake: 0.094 \n",
      "(epoch: 165, iters: 300, time: 0.022, data: 0.001) G_GAN: 2.365 G_L1: 26.902 D_real: 0.296 D_fake: 0.094 \n",
      "saving the model at the end of epoch 165, iters 57750\n",
      "End of epoch 165 / 200 \t Time Taken: 5 sec\n",
      "learning rate 0.0000693 -> 0.0000673\n",
      "(epoch: 166, iters: 50, time: 0.021, data: 0.000) G_GAN: 1.430 G_L1: 25.788 D_real: 0.121 D_fake: 0.435 \n",
      "(epoch: 166, iters: 150, time: 0.021, data: 0.001) G_GAN: 2.399 G_L1: 30.307 D_real: 0.032 D_fake: 0.257 \n",
      "(epoch: 166, iters: 250, time: 0.232, data: 0.000) G_GAN: 1.000 G_L1: 26.007 D_real: 0.754 D_fake: 0.460 \n",
      "(epoch: 166, iters: 350, time: 0.022, data: 0.001) G_GAN: 2.606 G_L1: 28.766 D_real: 0.016 D_fake: 0.305 \n",
      "End of epoch 166 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000673 -> 0.0000653\n",
      "(epoch: 167, iters: 100, time: 0.021, data: 0.050) G_GAN: 2.357 G_L1: 24.939 D_real: 0.791 D_fake: 0.107 \n",
      "(epoch: 167, iters: 200, time: 0.021, data: 0.000) G_GAN: 1.246 G_L1: 22.171 D_real: 1.111 D_fake: 0.169 \n",
      "(epoch: 167, iters: 300, time: 0.116, data: 0.000) G_GAN: 1.381 G_L1: 28.023 D_real: 0.702 D_fake: 0.270 \n",
      "End of epoch 167 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000653 -> 0.0000634\n",
      "(epoch: 168, iters: 50, time: 0.021, data: 0.001) G_GAN: 1.392 G_L1: 25.530 D_real: 0.547 D_fake: 0.438 \n",
      "(epoch: 168, iters: 150, time: 0.021, data: 0.000) G_GAN: 1.341 G_L1: 22.528 D_real: 0.633 D_fake: 0.245 \n",
      "(epoch: 168, iters: 250, time: 0.022, data: 0.000) G_GAN: 1.744 G_L1: 27.537 D_real: 0.539 D_fake: 0.257 \n",
      "(epoch: 168, iters: 350, time: 0.118, data: 0.000) G_GAN: 2.158 G_L1: 22.032 D_real: 0.161 D_fake: 0.179 \n",
      "End of epoch 168 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000634 -> 0.0000614\n",
      "(epoch: 169, iters: 100, time: 0.021, data: 0.048) G_GAN: 1.769 G_L1: 27.641 D_real: 0.369 D_fake: 0.215 \n",
      "(epoch: 169, iters: 200, time: 0.021, data: 0.000) G_GAN: 1.648 G_L1: 26.218 D_real: 2.281 D_fake: 0.112 \n",
      "(epoch: 169, iters: 300, time: 0.021, data: 0.000) G_GAN: 2.410 G_L1: 29.222 D_real: 0.141 D_fake: 0.145 \n",
      "End of epoch 169 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000614 -> 0.0000594\n",
      "(epoch: 170, iters: 50, time: 0.118, data: 0.000) G_GAN: 1.792 G_L1: 27.783 D_real: 0.466 D_fake: 0.340 \n",
      "(epoch: 170, iters: 150, time: 0.023, data: 0.001) G_GAN: 1.400 G_L1: 27.232 D_real: 0.888 D_fake: 0.241 \n",
      "(epoch: 170, iters: 250, time: 0.021, data: 0.000) G_GAN: 2.007 G_L1: 24.716 D_real: 0.347 D_fake: 0.215 \n",
      "(epoch: 170, iters: 350, time: 0.022, data: 0.001) G_GAN: 1.944 G_L1: 28.416 D_real: 0.195 D_fake: 0.254 \n",
      "saving the model at the end of epoch 170, iters 59500\n",
      "End of epoch 170 / 200 \t Time Taken: 5 sec\n",
      "learning rate 0.0000594 -> 0.0000574\n",
      "(epoch: 171, iters: 100, time: 0.118, data: 0.059) G_GAN: 1.845 G_L1: 19.372 D_real: 0.506 D_fake: 0.180 \n",
      "(epoch: 171, iters: 200, time: 0.021, data: 0.001) G_GAN: 2.265 G_L1: 25.579 D_real: 0.104 D_fake: 0.343 \n",
      "(epoch: 171, iters: 300, time: 0.022, data: 0.000) G_GAN: 1.414 G_L1: 26.238 D_real: 0.717 D_fake: 0.315 \n",
      "End of epoch 171 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000574 -> 0.0000554\n",
      "(epoch: 172, iters: 50, time: 0.021, data: 0.001) G_GAN: 1.548 G_L1: 30.261 D_real: 0.016 D_fake: 0.562 \n",
      "(epoch: 172, iters: 150, time: 0.117, data: 0.000) G_GAN: 2.231 G_L1: 30.342 D_real: 0.185 D_fake: 0.173 \n",
      "saving the latest model (epoch 172, total_iters 60000)\n",
      "(epoch: 172, iters: 250, time: 0.022, data: 0.001) G_GAN: 1.660 G_L1: 26.857 D_real: 1.254 D_fake: 0.247 \n",
      "(epoch: 172, iters: 350, time: 0.023, data: 0.000) G_GAN: 1.553 G_L1: 26.875 D_real: 0.253 D_fake: 0.556 \n",
      "End of epoch 172 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000554 -> 0.0000535\n",
      "(epoch: 173, iters: 100, time: 0.021, data: 0.052) G_GAN: 1.165 G_L1: 27.654 D_real: 0.592 D_fake: 0.472 \n",
      "(epoch: 173, iters: 200, time: 0.120, data: 0.000) G_GAN: 2.856 G_L1: 24.896 D_real: 0.346 D_fake: 0.069 \n",
      "(epoch: 173, iters: 300, time: 0.022, data: 0.001) G_GAN: 2.440 G_L1: 28.105 D_real: 0.146 D_fake: 0.167 \n",
      "End of epoch 173 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000535 -> 0.0000515\n",
      "(epoch: 174, iters: 50, time: 0.021, data: 0.001) G_GAN: 1.904 G_L1: 24.884 D_real: 0.050 D_fake: 0.284 \n",
      "(epoch: 174, iters: 150, time: 0.021, data: 0.000) G_GAN: 1.582 G_L1: 24.892 D_real: 0.504 D_fake: 0.276 \n",
      "(epoch: 174, iters: 250, time: 0.239, data: 0.001) G_GAN: 1.881 G_L1: 26.909 D_real: 1.364 D_fake: 0.144 \n",
      "(epoch: 174, iters: 350, time: 0.023, data: 0.001) G_GAN: 2.159 G_L1: 30.095 D_real: 0.178 D_fake: 0.203 \n",
      "End of epoch 174 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000515 -> 0.0000495\n",
      "(epoch: 175, iters: 100, time: 0.022, data: 0.046) G_GAN: 1.360 G_L1: 27.896 D_real: 0.078 D_fake: 0.943 \n",
      "(epoch: 175, iters: 200, time: 0.021, data: 0.001) G_GAN: 1.886 G_L1: 26.918 D_real: 0.345 D_fake: 0.218 \n",
      "(epoch: 175, iters: 300, time: 0.120, data: 0.001) G_GAN: 1.722 G_L1: 27.847 D_real: 0.207 D_fake: 0.626 \n",
      "saving the model at the end of epoch 175, iters 61250\n",
      "End of epoch 175 / 200 \t Time Taken: 5 sec\n",
      "learning rate 0.0000495 -> 0.0000475\n",
      "(epoch: 176, iters: 50, time: 0.021, data: 0.001) G_GAN: 0.976 G_L1: 27.697 D_real: 1.796 D_fake: 0.283 \n",
      "(epoch: 176, iters: 150, time: 0.021, data: 0.000) G_GAN: 1.404 G_L1: 28.181 D_real: 0.464 D_fake: 0.311 \n",
      "(epoch: 176, iters: 250, time: 0.022, data: 0.000) G_GAN: 1.580 G_L1: 27.495 D_real: 0.055 D_fake: 0.954 \n",
      "(epoch: 176, iters: 350, time: 0.123, data: 0.001) G_GAN: 1.496 G_L1: 29.715 D_real: 0.022 D_fake: 0.628 \n",
      "End of epoch 176 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000475 -> 0.0000455\n",
      "(epoch: 177, iters: 100, time: 0.022, data: 0.045) G_GAN: 1.750 G_L1: 27.430 D_real: 0.183 D_fake: 0.329 \n",
      "(epoch: 177, iters: 200, time: 0.021, data: 0.000) G_GAN: 1.501 G_L1: 26.295 D_real: 0.397 D_fake: 0.440 \n",
      "(epoch: 177, iters: 300, time: 0.022, data: 0.000) G_GAN: 1.823 G_L1: 25.917 D_real: 0.214 D_fake: 0.313 \n",
      "End of epoch 177 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000455 -> 0.0000436\n",
      "(epoch: 178, iters: 50, time: 0.121, data: 0.000) G_GAN: 1.249 G_L1: 30.335 D_real: 0.212 D_fake: 0.956 \n",
      "(epoch: 178, iters: 150, time: 0.021, data: 0.001) G_GAN: 1.202 G_L1: 24.539 D_real: 0.417 D_fake: 0.494 \n",
      "(epoch: 178, iters: 250, time: 0.022, data: 0.001) G_GAN: 1.995 G_L1: 27.652 D_real: 0.104 D_fake: 0.210 \n",
      "(epoch: 178, iters: 350, time: 0.021, data: 0.001) G_GAN: 1.805 G_L1: 24.442 D_real: 0.233 D_fake: 0.362 \n",
      "End of epoch 178 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000436 -> 0.0000416\n",
      "(epoch: 179, iters: 100, time: 0.120, data: 0.045) G_GAN: 1.242 G_L1: 27.330 D_real: 0.028 D_fake: 0.904 \n",
      "(epoch: 179, iters: 200, time: 0.021, data: 0.001) G_GAN: 1.805 G_L1: 26.760 D_real: 0.424 D_fake: 0.222 \n",
      "(epoch: 179, iters: 300, time: 0.021, data: 0.000) G_GAN: 3.181 G_L1: 24.691 D_real: 0.320 D_fake: 0.072 \n",
      "End of epoch 179 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000416 -> 0.0000396\n",
      "(epoch: 180, iters: 50, time: 0.022, data: 0.000) G_GAN: 1.675 G_L1: 29.015 D_real: 0.407 D_fake: 0.325 \n",
      "(epoch: 180, iters: 150, time: 0.128, data: 0.001) G_GAN: 1.684 G_L1: 24.794 D_real: 0.229 D_fake: 0.275 \n",
      "(epoch: 180, iters: 250, time: 0.022, data: 0.001) G_GAN: 1.762 G_L1: 23.567 D_real: 0.519 D_fake: 0.253 \n",
      "(epoch: 180, iters: 350, time: 0.022, data: 0.000) G_GAN: 1.073 G_L1: 26.441 D_real: 0.261 D_fake: 0.675 \n",
      "saving the model at the end of epoch 180, iters 63000\n",
      "End of epoch 180 / 200 \t Time Taken: 5 sec\n",
      "learning rate 0.0000396 -> 0.0000376\n",
      "(epoch: 181, iters: 100, time: 0.021, data: 0.063) G_GAN: 1.476 G_L1: 27.174 D_real: 0.289 D_fake: 0.370 \n",
      "(epoch: 181, iters: 200, time: 0.238, data: 0.001) G_GAN: 1.723 G_L1: 29.290 D_real: 0.218 D_fake: 0.356 \n",
      "(epoch: 181, iters: 300, time: 0.022, data: 0.001) G_GAN: 2.059 G_L1: 28.204 D_real: 0.099 D_fake: 0.299 \n",
      "End of epoch 181 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000376 -> 0.0000356\n",
      "(epoch: 182, iters: 50, time: 0.022, data: 0.000) G_GAN: 1.685 G_L1: 24.408 D_real: 0.867 D_fake: 0.170 \n",
      "(epoch: 182, iters: 150, time: 0.022, data: 0.001) G_GAN: 2.945 G_L1: 24.558 D_real: 0.541 D_fake: 0.058 \n",
      "(epoch: 182, iters: 250, time: 0.121, data: 0.001) G_GAN: 2.089 G_L1: 29.378 D_real: 0.220 D_fake: 0.235 \n",
      "(epoch: 182, iters: 350, time: 0.021, data: 0.001) G_GAN: 2.321 G_L1: 21.002 D_real: 0.069 D_fake: 0.323 \n",
      "End of epoch 182 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000356 -> 0.0000337\n",
      "(epoch: 183, iters: 100, time: 0.022, data: 0.049) G_GAN: 1.684 G_L1: 27.849 D_real: 0.034 D_fake: 0.362 \n",
      "(epoch: 183, iters: 200, time: 0.021, data: 0.001) G_GAN: 1.548 G_L1: 26.745 D_real: 0.401 D_fake: 0.339 \n",
      "(epoch: 183, iters: 300, time: 0.122, data: 0.000) G_GAN: 1.307 G_L1: 26.742 D_real: 0.267 D_fake: 0.505 \n",
      "End of epoch 183 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000337 -> 0.0000317\n",
      "(epoch: 184, iters: 50, time: 0.022, data: 0.001) G_GAN: 2.108 G_L1: 26.033 D_real: 0.709 D_fake: 0.115 \n",
      "(epoch: 184, iters: 150, time: 0.022, data: 0.000) G_GAN: 2.531 G_L1: 27.809 D_real: 0.911 D_fake: 0.083 \n",
      "(epoch: 184, iters: 250, time: 0.021, data: 0.001) G_GAN: 1.518 G_L1: 22.767 D_real: 0.680 D_fake: 0.304 \n",
      "(epoch: 184, iters: 350, time: 0.123, data: 0.000) G_GAN: 2.166 G_L1: 24.967 D_real: 0.037 D_fake: 0.219 \n",
      "End of epoch 184 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000317 -> 0.0000297\n",
      "(epoch: 185, iters: 100, time: 0.023, data: 0.048) G_GAN: 2.109 G_L1: 26.186 D_real: 0.593 D_fake: 0.155 \n",
      "(epoch: 185, iters: 200, time: 0.021, data: 0.001) G_GAN: 1.249 G_L1: 29.728 D_real: 0.175 D_fake: 0.544 \n",
      "(epoch: 185, iters: 300, time: 0.021, data: 0.000) G_GAN: 1.505 G_L1: 28.262 D_real: 0.323 D_fake: 0.456 \n",
      "saving the model at the end of epoch 185, iters 64750\n",
      "End of epoch 185 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000297 -> 0.0000277\n",
      "(epoch: 186, iters: 50, time: 0.126, data: 0.000) G_GAN: 1.231 G_L1: 31.032 D_real: 0.027 D_fake: 0.737 \n",
      "(epoch: 186, iters: 150, time: 0.023, data: 0.001) G_GAN: 2.244 G_L1: 23.526 D_real: 0.510 D_fake: 0.126 \n",
      "(epoch: 186, iters: 250, time: 0.021, data: 0.001) G_GAN: 2.853 G_L1: 22.527 D_real: 0.078 D_fake: 0.102 \n",
      "saving the latest model (epoch 186, total_iters 65000)\n",
      "(epoch: 186, iters: 350, time: 0.021, data: 0.001) G_GAN: 1.158 G_L1: 29.404 D_real: 0.089 D_fake: 0.840 \n",
      "End of epoch 186 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000277 -> 0.0000257\n",
      "(epoch: 187, iters: 100, time: 0.123, data: 0.060) G_GAN: 1.567 G_L1: 30.770 D_real: 0.598 D_fake: 0.302 \n",
      "(epoch: 187, iters: 200, time: 0.021, data: 0.001) G_GAN: 1.797 G_L1: 28.102 D_real: 0.036 D_fake: 0.365 \n",
      "(epoch: 187, iters: 300, time: 0.023, data: 0.000) G_GAN: 2.262 G_L1: 25.859 D_real: 0.245 D_fake: 0.169 \n",
      "End of epoch 187 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000257 -> 0.0000238\n",
      "(epoch: 188, iters: 50, time: 0.021, data: 0.001) G_GAN: 1.386 G_L1: 23.110 D_real: 0.596 D_fake: 0.345 \n",
      "(epoch: 188, iters: 150, time: 0.242, data: 0.000) G_GAN: 2.482 G_L1: 30.352 D_real: 0.036 D_fake: 0.141 \n",
      "(epoch: 188, iters: 250, time: 0.021, data: 0.001) G_GAN: 1.646 G_L1: 28.397 D_real: 0.068 D_fake: 0.439 \n",
      "(epoch: 188, iters: 350, time: 0.023, data: 0.000) G_GAN: 1.954 G_L1: 19.235 D_real: 0.982 D_fake: 0.118 \n",
      "End of epoch 188 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000238 -> 0.0000218\n",
      "(epoch: 189, iters: 100, time: 0.021, data: 0.056) G_GAN: 1.438 G_L1: 23.837 D_real: 0.586 D_fake: 0.297 \n",
      "(epoch: 189, iters: 200, time: 0.126, data: 0.001) G_GAN: 2.156 G_L1: 25.807 D_real: 0.266 D_fake: 0.164 \n",
      "(epoch: 189, iters: 300, time: 0.021, data: 0.001) G_GAN: 1.366 G_L1: 28.641 D_real: 0.359 D_fake: 0.429 \n",
      "End of epoch 189 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000218 -> 0.0000198\n",
      "(epoch: 190, iters: 50, time: 0.023, data: 0.001) G_GAN: 1.481 G_L1: 28.013 D_real: 0.083 D_fake: 0.463 \n",
      "(epoch: 190, iters: 150, time: 0.022, data: 0.000) G_GAN: 1.671 G_L1: 25.275 D_real: 0.085 D_fake: 0.408 \n",
      "(epoch: 190, iters: 250, time: 0.125, data: 0.000) G_GAN: 2.467 G_L1: 26.481 D_real: 0.429 D_fake: 0.119 \n",
      "(epoch: 190, iters: 350, time: 0.021, data: 0.001) G_GAN: 1.309 G_L1: 28.854 D_real: 0.077 D_fake: 0.546 \n",
      "saving the model at the end of epoch 190, iters 66500\n",
      "End of epoch 190 / 200 \t Time Taken: 5 sec\n",
      "learning rate 0.0000198 -> 0.0000178\n",
      "(epoch: 191, iters: 100, time: 0.022, data: 0.059) G_GAN: 1.818 G_L1: 23.071 D_real: 0.766 D_fake: 0.208 \n",
      "(epoch: 191, iters: 200, time: 0.022, data: 0.000) G_GAN: 2.131 G_L1: 25.692 D_real: 0.250 D_fake: 0.199 \n",
      "(epoch: 191, iters: 300, time: 0.129, data: 0.000) G_GAN: 1.153 G_L1: 25.562 D_real: 0.517 D_fake: 0.552 \n",
      "End of epoch 191 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000178 -> 0.0000158\n",
      "(epoch: 192, iters: 50, time: 0.021, data: 0.001) G_GAN: 1.250 G_L1: 20.777 D_real: 0.301 D_fake: 0.668 \n",
      "(epoch: 192, iters: 150, time: 0.021, data: 0.000) G_GAN: 1.544 G_L1: 17.827 D_real: 0.614 D_fake: 0.319 \n",
      "(epoch: 192, iters: 250, time: 0.022, data: 0.000) G_GAN: 2.763 G_L1: 24.986 D_real: 0.389 D_fake: 0.091 \n",
      "(epoch: 192, iters: 350, time: 0.132, data: 0.000) G_GAN: 1.050 G_L1: 30.138 D_real: 0.054 D_fake: 0.717 \n",
      "End of epoch 192 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000158 -> 0.0000139\n",
      "(epoch: 193, iters: 100, time: 0.021, data: 0.051) G_GAN: 2.041 G_L1: 27.515 D_real: 0.785 D_fake: 0.162 \n",
      "(epoch: 193, iters: 200, time: 0.021, data: 0.001) G_GAN: 1.881 G_L1: 30.762 D_real: 0.270 D_fake: 0.241 \n",
      "(epoch: 193, iters: 300, time: 0.020, data: 0.001) G_GAN: 1.574 G_L1: 26.864 D_real: 0.553 D_fake: 0.271 \n",
      "End of epoch 193 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000139 -> 0.0000119\n",
      "(epoch: 194, iters: 50, time: 0.126, data: 0.001) G_GAN: 3.368 G_L1: 22.776 D_real: 0.484 D_fake: 0.048 \n",
      "(epoch: 194, iters: 150, time: 0.021, data: 0.001) G_GAN: 1.138 G_L1: 30.802 D_real: 0.169 D_fake: 0.644 \n",
      "(epoch: 194, iters: 250, time: 0.022, data: 0.000) G_GAN: 2.010 G_L1: 26.065 D_real: 0.137 D_fake: 0.209 \n",
      "(epoch: 194, iters: 350, time: 0.021, data: 0.001) G_GAN: 1.243 G_L1: 29.180 D_real: 0.350 D_fake: 0.533 \n",
      "End of epoch 194 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000119 -> 0.0000099\n",
      "(epoch: 195, iters: 100, time: 0.239, data: 0.047) G_GAN: 2.072 G_L1: 25.712 D_real: 0.327 D_fake: 0.201 \n",
      "(epoch: 195, iters: 200, time: 0.021, data: 0.001) G_GAN: 1.417 G_L1: 24.962 D_real: 1.128 D_fake: 0.341 \n",
      "(epoch: 195, iters: 300, time: 0.022, data: 0.000) G_GAN: 1.494 G_L1: 26.417 D_real: 0.145 D_fake: 0.356 \n",
      "saving the model at the end of epoch 195, iters 68250\n",
      "End of epoch 195 / 200 \t Time Taken: 5 sec\n",
      "learning rate 0.0000099 -> 0.0000079\n",
      "(epoch: 196, iters: 50, time: 0.021, data: 0.000) G_GAN: 1.647 G_L1: 29.803 D_real: 0.217 D_fake: 0.327 \n",
      "(epoch: 196, iters: 150, time: 0.129, data: 0.000) G_GAN: 1.681 G_L1: 28.609 D_real: 0.233 D_fake: 0.286 \n",
      "(epoch: 196, iters: 250, time: 0.022, data: 0.001) G_GAN: 1.459 G_L1: 27.008 D_real: 0.374 D_fake: 0.460 \n",
      "(epoch: 196, iters: 350, time: 0.021, data: 0.000) G_GAN: 1.615 G_L1: 24.938 D_real: 0.293 D_fake: 0.327 \n",
      "End of epoch 196 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000079 -> 0.0000059\n",
      "(epoch: 197, iters: 100, time: 0.021, data: 0.046) G_GAN: 1.709 G_L1: 29.553 D_real: 0.032 D_fake: 0.342 \n",
      "(epoch: 197, iters: 200, time: 0.128, data: 0.001) G_GAN: 1.886 G_L1: 25.920 D_real: 0.426 D_fake: 0.340 \n",
      "(epoch: 197, iters: 300, time: 0.021, data: 0.001) G_GAN: 1.892 G_L1: 25.857 D_real: 0.388 D_fake: 0.237 \n",
      "End of epoch 197 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000059 -> 0.0000040\n",
      "(epoch: 198, iters: 50, time: 0.022, data: 0.001) G_GAN: 2.073 G_L1: 28.710 D_real: 0.236 D_fake: 0.191 \n",
      "(epoch: 198, iters: 150, time: 0.021, data: 0.000) G_GAN: 1.972 G_L1: 27.679 D_real: 0.444 D_fake: 0.235 \n",
      "(epoch: 198, iters: 250, time: 0.130, data: 0.000) G_GAN: 1.456 G_L1: 27.065 D_real: 0.497 D_fake: 0.340 \n",
      "(epoch: 198, iters: 350, time: 0.021, data: 0.001) G_GAN: 2.062 G_L1: 26.872 D_real: 0.062 D_fake: 0.199 \n",
      "End of epoch 198 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000040 -> 0.0000020\n",
      "(epoch: 199, iters: 100, time: 0.022, data: 0.049) G_GAN: 1.809 G_L1: 29.857 D_real: 0.105 D_fake: 0.283 \n",
      "(epoch: 199, iters: 200, time: 0.021, data: 0.000) G_GAN: 0.961 G_L1: 27.882 D_real: 0.116 D_fake: 0.660 \n",
      "(epoch: 199, iters: 300, time: 0.129, data: 0.000) G_GAN: 1.752 G_L1: 24.956 D_real: 0.222 D_fake: 0.256 \n",
      "End of epoch 199 / 200 \t Time Taken: 4 sec\n",
      "learning rate 0.0000020 -> 0.0000000\n",
      "(epoch: 200, iters: 50, time: 0.022, data: 0.001) G_GAN: 0.651 G_L1: 30.967 D_real: 0.121 D_fake: 0.969 \n",
      "(epoch: 200, iters: 150, time: 0.021, data: 0.001) G_GAN: 2.042 G_L1: 27.077 D_real: 0.453 D_fake: 0.204 \n",
      "(epoch: 200, iters: 250, time: 0.023, data: 0.000) G_GAN: 1.163 G_L1: 26.340 D_real: 0.012 D_fake: 0.518 \n",
      "(epoch: 200, iters: 350, time: 0.129, data: 0.001) G_GAN: 2.107 G_L1: 25.750 D_real: 0.416 D_fake: 0.191 \n",
      "saving the latest model (epoch 200, total_iters 70000)\n",
      "saving the model at the end of epoch 200, iters 70000\n",
      "End of epoch 200 / 200 \t Time Taken: 5 sec\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot ./datasets/dataset_for_GAN --name dataset_for_GAN_pix2pix --model pix2pix --direction AtoB --display_id -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9UkcaFZiyASl"
   },
   "source": [
    "# Testing\n",
    "\n",
    "-   `python test.py --dataroot ./datasets/facades --direction BtoA --model pix2pix --name facades_pix2pix`\n",
    "\n",
    "Change the `--dataroot`, `--name`, and `--direction` to be consistent with your trained model's configuration and how you want to transform images.\n",
    "\n",
    "> from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix:\n",
    "> Note that we specified --direction BtoA as Facades dataset's A to B direction is photos to labels.\n",
    "\n",
    "> If you would like to apply a pre-trained model to a collection of input images (rather than image pairs), please use --model test option. See ./scripts/test_single.sh for how to apply a model to Facade label maps (stored in the directory facades/testB).\n",
    "\n",
    "> See a list of currently available models at ./scripts/download_pix2pix_model.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mey7o6j-0368"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_for_GAN_pix2pix  facades_label2photo_pretrained\n"
     ]
    }
   ],
   "source": [
    "!ls checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uCsKkEq0yGh0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                crop_size: 256                           \n",
      "                 dataroot: /home/omerfarukaydin/Desktop/OCTA_500_dataset_for_GAN_pix2pix\t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: test]\n",
      "               n_layers_D: 3                             \n",
      "                     name: dataset_for_GAN_pix2pix       \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \n",
      "                 num_test: 75                            \t[default: 50]\n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: test                          \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: ./results/                    \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "loading the model from ./checkpoints/dataset_for_GAN_pix2pix/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "-----------------------------------------------\n",
      "creating web directory ./results/dataset_for_GAN_pix2pix/test_latest\n",
      "processing (0000)-th image... ['/home/omerfarukaydin/Desktop/OCTA_500_dataset_for_GAN_pix2pix/test/10002.jpg']\n",
      "processing (0005)-th image... ['/home/omerfarukaydin/Desktop/OCTA_500_dataset_for_GAN_pix2pix/test/10034.jpg']\n",
      "processing (0010)-th image... ['/home/omerfarukaydin/Desktop/OCTA_500_dataset_for_GAN_pix2pix/test/10073.jpg']\n",
      "processing (0015)-th image... ['/home/omerfarukaydin/Desktop/OCTA_500_dataset_for_GAN_pix2pix/test/10108.jpg']\n",
      "processing (0020)-th image... ['/home/omerfarukaydin/Desktop/OCTA_500_dataset_for_GAN_pix2pix/test/10144.jpg']\n",
      "processing (0025)-th image... ['/home/omerfarukaydin/Desktop/OCTA_500_dataset_for_GAN_pix2pix/test/10162.jpg']\n",
      "processing (0030)-th image... ['/home/omerfarukaydin/Desktop/OCTA_500_dataset_for_GAN_pix2pix/test/10197.jpg']\n",
      "processing (0035)-th image... ['/home/omerfarukaydin/Desktop/OCTA_500_dataset_for_GAN_pix2pix/test/10261.jpg']\n",
      "processing (0040)-th image... ['/home/omerfarukaydin/Desktop/OCTA_500_dataset_for_GAN_pix2pix/test/10275.jpg']\n",
      "processing (0045)-th image... ['/home/omerfarukaydin/Desktop/OCTA_500_dataset_for_GAN_pix2pix/test/10299.jpg']\n",
      "processing (0050)-th image... ['/home/omerfarukaydin/Desktop/OCTA_500_dataset_for_GAN_pix2pix/test/10318.jpg']\n",
      "processing (0055)-th image... ['/home/omerfarukaydin/Desktop/OCTA_500_dataset_for_GAN_pix2pix/test/10353.jpg']\n",
      "processing (0060)-th image... ['/home/omerfarukaydin/Desktop/OCTA_500_dataset_for_GAN_pix2pix/test/10389.jpg']\n",
      "processing (0065)-th image... ['/home/omerfarukaydin/Desktop/OCTA_500_dataset_for_GAN_pix2pix/test/10453.jpg']\n",
      "processing (0070)-th image... ['/home/omerfarukaydin/Desktop/OCTA_500_dataset_for_GAN_pix2pix/test/10484.jpg']\n"
     ]
    }
   ],
   "source": [
    "!python test.py --dataroot /home/omerfarukaydin/Desktop/OCTA_500_dataset_for_GAN_pix2pix --direction AtoB --model pix2pix --name dataset_for_GAN_pix2pix --num_test 75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OzSKIPUByfiN"
   },
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Mgg8raPyizq"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_fake_B.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0G3oVH9DyqLQ"
   },
   "outputs": [],
   "source": [
    "img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_real_A.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ErK5OC1j1LH4"
   },
   "outputs": [],
   "source": [
    "img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_real_B.png')\n",
    "plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "pix2pix",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-3.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
